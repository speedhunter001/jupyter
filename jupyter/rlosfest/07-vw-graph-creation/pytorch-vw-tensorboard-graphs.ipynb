{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vowpalwabbit import pyvw\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gd', 'scorer', 'csoaa_ldf', 'cb_adf', 'shared_feature_merger', 'cb_to_cbadf']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vw = pyvw.vw('--cb 3 -P 1')\n",
    "vw.get_enabled_reductions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorboardX as tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")  # logs directory\n",
    "file_writer = tx.SummaryWriter(logdir+'/iris', flush_secs=5)   # creating file writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muhammadammarabid/anaconda3/lib/python3.8/site-packages/setuptools/distutils_patch.py:25: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'vw' object has no attribute 'training'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e2ab1daf4b2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfile_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorboardX/writer.py\u001b[0m in \u001b[0;36madd_graph\u001b[0;34m(self, model, input_to_model, verbose)\u001b[0m\n\u001b[1;32m    899\u001b[0m         \"\"\"\n\u001b[1;32m    900\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pytorch_graph\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_file_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_to_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m     def add_graph_deprecated(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/tensorboard/_pytorch_graph.py\u001b[0m in \u001b[0;36mgraph\u001b[0;34m(model, args, verbose)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0mprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \"\"\"\n\u001b[0;32m--> 284\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_model_mode_for_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainingMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEVAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# TODO: move outside of torch.onnx?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36mselect_model_mode_for_export\u001b[0;34m(model, mode)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mselect_model_mode_for_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScriptFunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mis_originally_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'vw' object has no attribute 'training'"
     ]
    }
   ],
   "source": [
    "file_writer.add_graph(vw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%self.1 : __torch__.___torch_mangle_3.LinearInLinear,\n",
      "      %x : Float(1, 3, strides=[3, 1], requires_grad=0, device=cpu)):\n",
      "  %13 : __torch__.torch.nn.modules.linear.___torch_mangle_2.Linear = prim::GetAttr[name=\"l\"](%self.1)\n",
      "  %16 : Tensor = prim::GetAttr[name=\"bias\"](%13)\n",
      "  %17 : Tensor = prim::GetAttr[name=\"weight\"](%13)\n",
      "  %18 : Float(1, 5, strides=[5, 1], requires_grad=1, device=cpu) = aten::linear(%x, %17, %16), scope: __module.l # /home/muhammadammarabid/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1847:0\n",
      "  return (%18)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "dummy_input = (torch.zeros(1, 3),)\n",
    "\n",
    "\n",
    "class LinearInLinear(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearInLinear, self).__init__()\n",
    "        self.l = nn.Linear(3, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.l(x)\n",
    "\n",
    "with SummaryWriter(comment='LinearInLinear') as w:\n",
    "    w.add_graph(LinearInLinear(), dummy_input, True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Graph in module tensorflow.python.framework.ops:\n",
      "\n",
      "class Graph(builtins.object)\n",
      " |  A TensorFlow computation, represented as a dataflow graph.\n",
      " |  \n",
      " |  Graphs are used by `tf.function`s to represent the function's computations.\n",
      " |  Each graph contains a set of `tf.Operation` objects, which represent units of\n",
      " |  computation; and `tf.Tensor` objects, which represent the units of data that\n",
      " |  flow between operations.\n",
      " |  \n",
      " |  ### Using graphs directly (deprecated)\n",
      " |  \n",
      " |  A `tf.Graph` can be constructed and used directly without a `tf.function`, as\n",
      " |  was required in TensorFlow 1, but this is deprecated and it is recommended to\n",
      " |  use a `tf.function` instead. If a graph is directly used, other deprecated\n",
      " |  TensorFlow 1 classes are also required to execute the graph, such as a\n",
      " |  `tf.compat.v1.Session`.\n",
      " |  \n",
      " |  A default graph can be registered with the `tf.Graph.as_default` context\n",
      " |  manager. Then, operations will be added to the graph instead of being executed\n",
      " |  eagerly. For example:\n",
      " |  \n",
      " |  ```python\n",
      " |  g = tf.Graph()\n",
      " |  with g.as_default():\n",
      " |    # Define operations and tensors in `g`.\n",
      " |    c = tf.constant(30.0)\n",
      " |    assert c.graph is g\n",
      " |  ```\n",
      " |  \n",
      " |  `tf.compat.v1.get_default_graph()` can be used to obtain the default graph.\n",
      " |  \n",
      " |  Important note: This class *is not* thread-safe for graph construction. All\n",
      " |  operations should be created from a single thread, or external\n",
      " |  synchronization must be provided. Unless otherwise specified, all methods\n",
      " |  are not thread-safe.\n",
      " |  \n",
      " |  A `Graph` instance supports an arbitrary number of \"collections\"\n",
      " |  that are identified by name. For convenience when building a large\n",
      " |  graph, collections can store groups of related objects: for\n",
      " |  example, the `tf.Variable` uses a collection (named\n",
      " |  `tf.GraphKeys.GLOBAL_VARIABLES`) for\n",
      " |  all variables that are created during the construction of a graph. The caller\n",
      " |  may define additional collections by specifying a new name.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self)\n",
      " |      Creates a new, empty Graph.\n",
      " |  \n",
      " |  add_to_collection(self, name, value)\n",
      " |      Stores `value` in the collection with the given `name`.\n",
      " |      \n",
      " |      Note that collections are not sets, so it is possible to add a value to\n",
      " |      a collection several times.\n",
      " |      \n",
      " |      Args:\n",
      " |        name: The key for the collection. The `GraphKeys` class contains many\n",
      " |          standard names for collections.\n",
      " |        value: The value to add to the collection.\n",
      " |  \n",
      " |  add_to_collections(self, names, value)\n",
      " |      Stores `value` in the collections given by `names`.\n",
      " |      \n",
      " |      Note that collections are not sets, so it is possible to add a value to\n",
      " |      a collection several times. This function makes sure that duplicates in\n",
      " |      `names` are ignored, but it will not check for pre-existing membership of\n",
      " |      `value` in any of the collections in `names`.\n",
      " |      \n",
      " |      `names` can be any iterable, but if `names` is a string, it is treated as a\n",
      " |      single collection name.\n",
      " |      \n",
      " |      Args:\n",
      " |        names: The keys for the collections to add to. The `GraphKeys` class\n",
      " |          contains many standard names for collections.\n",
      " |        value: The value to add to the collections.\n",
      " |  \n",
      " |  as_default(self)\n",
      " |      Returns a context manager that makes this `Graph` the default graph.\n",
      " |      \n",
      " |      This method should be used if you want to create multiple graphs\n",
      " |      in the same process. For convenience, a global default graph is\n",
      " |      provided, and all ops will be added to this graph if you do not\n",
      " |      create a new graph explicitly.\n",
      " |      \n",
      " |      Use this method with the `with` keyword to specify that ops created within\n",
      " |      the scope of a block should be added to this graph. In this case, once\n",
      " |      the scope of the `with` is exited, the previous default graph is set again\n",
      " |      as default. There is a stack, so it's ok to have multiple nested levels\n",
      " |      of `as_default` calls.\n",
      " |      \n",
      " |      The default graph is a property of the current thread. If you\n",
      " |      create a new thread, and wish to use the default graph in that\n",
      " |      thread, you must explicitly add a `with g.as_default():` in that\n",
      " |      thread's function.\n",
      " |      \n",
      " |      The following code examples are equivalent:\n",
      " |      \n",
      " |      ```python\n",
      " |      # 1. Using Graph.as_default():\n",
      " |      g = tf.Graph()\n",
      " |      with g.as_default():\n",
      " |        c = tf.constant(5.0)\n",
      " |        assert c.graph is g\n",
      " |      \n",
      " |      # 2. Constructing and making default:\n",
      " |      with tf.Graph().as_default() as g:\n",
      " |        c = tf.constant(5.0)\n",
      " |        assert c.graph is g\n",
      " |      ```\n",
      " |      \n",
      " |      If eager execution is enabled ops created under this context manager will be\n",
      " |      added to the graph instead of executed eagerly.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A context manager for using this graph as the default graph.\n",
      " |  \n",
      " |  as_graph_def(self, from_version=None, add_shapes=False)\n",
      " |      Returns a serialized `GraphDef` representation of this graph.\n",
      " |      \n",
      " |      The serialized `GraphDef` can be imported into another `Graph`\n",
      " |      (using `tf.import_graph_def`) or used with the\n",
      " |      [C++ Session API](../../api_docs/cc/index.md).\n",
      " |      \n",
      " |      This method is thread-safe.\n",
      " |      \n",
      " |      Args:\n",
      " |        from_version: Optional.  If this is set, returns a `GraphDef` containing\n",
      " |          only the nodes that were added to this graph since its `version`\n",
      " |          property had the given value.\n",
      " |        add_shapes: If true, adds an \"_output_shapes\" list attr to each node with\n",
      " |          the inferred shapes of each of its outputs.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A\n",
      " |        [`GraphDef`](https://www.tensorflow.org/code/tensorflow/core/framework/graph.proto)\n",
      " |        protocol buffer.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If the `graph_def` would be too large.\n",
      " |  \n",
      " |  as_graph_element(self, obj, allow_tensor=True, allow_operation=True)\n",
      " |      Returns the object referred to by `obj`, as an `Operation` or `Tensor`.\n",
      " |      \n",
      " |      This function validates that `obj` represents an element of this\n",
      " |      graph, and gives an informative error message if it is not.\n",
      " |      \n",
      " |      This function is the canonical way to get/validate an object of\n",
      " |      one of the allowed types from an external argument reference in the\n",
      " |      Session API.\n",
      " |      \n",
      " |      This method may be called concurrently from multiple threads.\n",
      " |      \n",
      " |      Args:\n",
      " |        obj: A `Tensor`, an `Operation`, or the name of a tensor or operation. Can\n",
      " |          also be any object with an `_as_graph_element()` method that returns a\n",
      " |          value of one of these types. Note: `_as_graph_element` will be called\n",
      " |          inside the graph's lock and so may not modify the graph.\n",
      " |        allow_tensor: If true, `obj` may refer to a `Tensor`.\n",
      " |        allow_operation: If true, `obj` may refer to an `Operation`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The `Tensor` or `Operation` in the Graph corresponding to `obj`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If `obj` is not a type we support attempting to convert\n",
      " |          to types.\n",
      " |        ValueError: If `obj` is of an appropriate type but invalid. For\n",
      " |          example, an invalid string.\n",
      " |        KeyError: If `obj` is not an object in the graph.\n",
      " |  \n",
      " |  clear_collection(self, name)\n",
      " |      Clears all values in a collection.\n",
      " |      \n",
      " |      Args:\n",
      " |        name: The key for the collection. The `GraphKeys` class contains many\n",
      " |          standard names for collections.\n",
      " |  \n",
      " |  colocate_with(self, op, ignore_existing=False)\n",
      " |      Returns a context manager that specifies an op to colocate with.\n",
      " |      \n",
      " |      Note: this function is not for public use, only for internal libraries.\n",
      " |      \n",
      " |      For example:\n",
      " |      \n",
      " |      ```python\n",
      " |      a = tf.Variable([1.0])\n",
      " |      with g.colocate_with(a):\n",
      " |        b = tf.constant(1.0)\n",
      " |        c = tf.add(a, b)\n",
      " |      ```\n",
      " |      \n",
      " |      `b` and `c` will always be colocated with `a`, no matter where `a`\n",
      " |      is eventually placed.\n",
      " |      \n",
      " |      **NOTE** Using a colocation scope resets any existing device constraints.\n",
      " |      \n",
      " |      If `op` is `None` then `ignore_existing` must be `True` and the new\n",
      " |      scope resets all colocation and device constraints.\n",
      " |      \n",
      " |      Args:\n",
      " |        op: The op to colocate all created ops with, or `None`.\n",
      " |        ignore_existing: If true, only applies colocation of this op within the\n",
      " |          context, rather than applying all colocation properties on the stack.\n",
      " |          If `op` is `None`, this value must be `True`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if op is None but ignore_existing is False.\n",
      " |      \n",
      " |      Yields:\n",
      " |        A context manager that specifies the op with which to colocate\n",
      " |        newly created ops.\n",
      " |  \n",
      " |  container(self, container_name)\n",
      " |      Returns a context manager that specifies the resource container to use.\n",
      " |      \n",
      " |      Stateful operations, such as variables and queues, can maintain their\n",
      " |      states on devices so that they can be shared by multiple processes.\n",
      " |      A resource container is a string name under which these stateful\n",
      " |      operations are tracked. These resources can be released or cleared\n",
      " |      with `tf.Session.reset()`.\n",
      " |      \n",
      " |      For example:\n",
      " |      \n",
      " |      ```python\n",
      " |      with g.container('experiment0'):\n",
      " |        # All stateful Operations constructed in this context will be placed\n",
      " |        # in resource container \"experiment0\".\n",
      " |        v1 = tf.Variable([1.0])\n",
      " |        v2 = tf.Variable([2.0])\n",
      " |        with g.container(\"experiment1\"):\n",
      " |          # All stateful Operations constructed in this context will be\n",
      " |          # placed in resource container \"experiment1\".\n",
      " |          v3 = tf.Variable([3.0])\n",
      " |          q1 = tf.queue.FIFOQueue(10, tf.float32)\n",
      " |        # All stateful Operations constructed in this context will be\n",
      " |        # be created in the \"experiment0\".\n",
      " |        v4 = tf.Variable([4.0])\n",
      " |        q1 = tf.queue.FIFOQueue(20, tf.float32)\n",
      " |        with g.container(\"\"):\n",
      " |          # All stateful Operations constructed in this context will be\n",
      " |          # be placed in the default resource container.\n",
      " |          v5 = tf.Variable([5.0])\n",
      " |          q3 = tf.queue.FIFOQueue(30, tf.float32)\n",
      " |      \n",
      " |      # Resets container \"experiment0\", after which the state of v1, v2, v4, q1\n",
      " |      # will become undefined (such as uninitialized).\n",
      " |      tf.Session.reset(target, [\"experiment0\"])\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        container_name: container name string.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A context manager for defining resource containers for stateful ops,\n",
      " |          yields the container name.\n",
      " |  \n",
      " |  control_dependencies(self, control_inputs)\n",
      " |      Returns a context manager that specifies control dependencies.\n",
      " |      \n",
      " |      Use with the `with` keyword to specify that all operations constructed\n",
      " |      within the context should have control dependencies on\n",
      " |      `control_inputs`. For example:\n",
      " |      \n",
      " |      ```python\n",
      " |      with g.control_dependencies([a, b, c]):\n",
      " |        # `d` and `e` will only run after `a`, `b`, and `c` have executed.\n",
      " |        d = ...\n",
      " |        e = ...\n",
      " |      ```\n",
      " |      \n",
      " |      Multiple calls to `control_dependencies()` can be nested, and in\n",
      " |      that case a new `Operation` will have control dependencies on the union\n",
      " |      of `control_inputs` from all active contexts.\n",
      " |      \n",
      " |      ```python\n",
      " |      with g.control_dependencies([a, b]):\n",
      " |        # Ops constructed here run after `a` and `b`.\n",
      " |        with g.control_dependencies([c, d]):\n",
      " |          # Ops constructed here run after `a`, `b`, `c`, and `d`.\n",
      " |      ```\n",
      " |      \n",
      " |      You can pass None to clear the control dependencies:\n",
      " |      \n",
      " |      ```python\n",
      " |      with g.control_dependencies([a, b]):\n",
      " |        # Ops constructed here run after `a` and `b`.\n",
      " |        with g.control_dependencies(None):\n",
      " |          # Ops constructed here run normally, not waiting for either `a` or `b`.\n",
      " |          with g.control_dependencies([c, d]):\n",
      " |            # Ops constructed here run after `c` and `d`, also not waiting\n",
      " |            # for either `a` or `b`.\n",
      " |      ```\n",
      " |      \n",
      " |      *N.B.* The control dependencies context applies *only* to ops that\n",
      " |      are constructed within the context. Merely using an op or tensor\n",
      " |      in the context does not add a control dependency. The following\n",
      " |      example illustrates this point:\n",
      " |      \n",
      " |      ```python\n",
      " |      # WRONG\n",
      " |      def my_func(pred, tensor):\n",
      " |        t = tf.matmul(tensor, tensor)\n",
      " |        with tf.control_dependencies([pred]):\n",
      " |          # The matmul op is created outside the context, so no control\n",
      " |          # dependency will be added.\n",
      " |          return t\n",
      " |      \n",
      " |      # RIGHT\n",
      " |      def my_func(pred, tensor):\n",
      " |        with tf.control_dependencies([pred]):\n",
      " |          # The matmul op is created in the context, so a control dependency\n",
      " |          # will be added.\n",
      " |          return tf.matmul(tensor, tensor)\n",
      " |      ```\n",
      " |      \n",
      " |      Also note that though execution of ops created under this scope will trigger\n",
      " |      execution of the dependencies, the ops created under this scope might still\n",
      " |      be pruned from a normal tensorflow graph. For example, in the following\n",
      " |      snippet of code the dependencies are never executed:\n",
      " |      \n",
      " |      ```python\n",
      " |        loss = model.loss()\n",
      " |        with tf.control_dependencies(dependencies):\n",
      " |          loss = loss + tf.constant(1)  # note: dependencies ignored in the\n",
      " |                                        # backward pass\n",
      " |        return tf.gradients(loss, model.variables)\n",
      " |      ```\n",
      " |      \n",
      " |      This is because evaluating the gradient graph does not require evaluating\n",
      " |      the constant(1) op created in the forward pass.\n",
      " |      \n",
      " |      Args:\n",
      " |        control_inputs: A list of `Operation` or `Tensor` objects which must be\n",
      " |          executed or computed before running the operations defined in the\n",
      " |          context.  Can also be `None` to clear the control dependencies.\n",
      " |      \n",
      " |      Returns:\n",
      " |       A context manager that specifies control dependencies for all\n",
      " |       operations constructed within the context.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If `control_inputs` is not a list of `Operation` or\n",
      " |          `Tensor` objects.\n",
      " |  \n",
      " |  create_op(self, op_type, inputs, dtypes=None, input_types=None, name=None, attrs=None, op_def=None, compute_shapes=True, compute_device=True)\n",
      " |      Creates an `Operation` in this graph. (deprecated arguments)\n",
      " |      \n",
      " |      Warning: SOME ARGUMENTS ARE DEPRECATED: `(compute_shapes)`. They will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Shapes are always computed; don't use the compute_shapes as it has no effect.\n",
      " |      \n",
      " |      This is a low-level interface for creating an `Operation`. Most\n",
      " |      programs will not call this method directly, and instead use the\n",
      " |      Python op constructors, such as `tf.constant()`, which add ops to\n",
      " |      the default graph.\n",
      " |      \n",
      " |      Args:\n",
      " |        op_type: The `Operation` type to create. This corresponds to the\n",
      " |          `OpDef.name` field for the proto that defines the operation.\n",
      " |        inputs: A list of `Tensor` objects that will be inputs to the `Operation`.\n",
      " |        dtypes: (Optional) A list of `DType` objects that will be the types of the\n",
      " |          tensors that the operation produces.\n",
      " |        input_types: (Optional.) A list of `DType`s that will be the types of the\n",
      " |          tensors that the operation consumes. By default, uses the base `DType`\n",
      " |          of each input in `inputs`. Operations that expect reference-typed inputs\n",
      " |          must specify `input_types` explicitly.\n",
      " |        name: (Optional.) A string name for the operation. If not specified, a\n",
      " |          name is generated based on `op_type`.\n",
      " |        attrs: (Optional.) A dictionary where the key is the attribute name (a\n",
      " |          string) and the value is the respective `attr` attribute of the\n",
      " |          `NodeDef` proto that will represent the operation (an `AttrValue`\n",
      " |          proto).\n",
      " |        op_def: (Optional.) The `OpDef` proto that describes the `op_type` that\n",
      " |          the operation will have.\n",
      " |        compute_shapes: (Optional.) Deprecated. Has no effect (shapes are always\n",
      " |          computed).\n",
      " |        compute_device: (Optional.) If True, device functions will be executed to\n",
      " |          compute the device property of the Operation.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: if any of the inputs is not a `Tensor`.\n",
      " |        ValueError: if colocation conflicts with existing device assignment.\n",
      " |      \n",
      " |      Returns:\n",
      " |        An `Operation` object.\n",
      " |  \n",
      " |  device(self, device_name_or_function)\n",
      " |      Returns a context manager that specifies the default device to use.\n",
      " |      \n",
      " |      The `device_name_or_function` argument may either be a device name\n",
      " |      string, a device function, or None:\n",
      " |      \n",
      " |      * If it is a device name string, all operations constructed in\n",
      " |        this context will be assigned to the device with that name, unless\n",
      " |        overridden by a nested `device()` context.\n",
      " |      * If it is a function, it will be treated as a function from\n",
      " |        Operation objects to device name strings, and invoked each time\n",
      " |        a new Operation is created. The Operation will be assigned to\n",
      " |        the device with the returned name.\n",
      " |      * If it is None, all `device()` invocations from the enclosing context\n",
      " |        will be ignored.\n",
      " |      \n",
      " |      For information about the valid syntax of device name strings, see\n",
      " |      the documentation in\n",
      " |      [`DeviceNameUtils`](https://www.tensorflow.org/code/tensorflow/core/util/device_name_utils.h).\n",
      " |      \n",
      " |      For example:\n",
      " |      \n",
      " |      ```python\n",
      " |      with g.device('/device:GPU:0'):\n",
      " |        # All operations constructed in this context will be placed\n",
      " |        # on GPU 0.\n",
      " |        with g.device(None):\n",
      " |          # All operations constructed in this context will have no\n",
      " |          # assigned device.\n",
      " |      \n",
      " |      # Defines a function from `Operation` to device string.\n",
      " |      def matmul_on_gpu(n):\n",
      " |        if n.type == \"MatMul\":\n",
      " |          return \"/device:GPU:0\"\n",
      " |        else:\n",
      " |          return \"/cpu:0\"\n",
      " |      \n",
      " |      with g.device(matmul_on_gpu):\n",
      " |        # All operations of type \"MatMul\" constructed in this context\n",
      " |        # will be placed on GPU 0; all other operations will be placed\n",
      " |        # on CPU 0.\n",
      " |      ```\n",
      " |      \n",
      " |      **N.B.** The device scope may be overridden by op wrappers or\n",
      " |      other library code. For example, a variable assignment op\n",
      " |      `v.assign()` must be colocated with the `tf.Variable` `v`, and\n",
      " |      incompatible device scopes will be ignored.\n",
      " |      \n",
      " |      Args:\n",
      " |        device_name_or_function: The device name or function to use in the\n",
      " |          context.\n",
      " |      \n",
      " |      Yields:\n",
      " |        A context manager that specifies the default device to use for newly\n",
      " |        created ops.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If device scopes are not properly nested.\n",
      " |  \n",
      " |  finalize(self)\n",
      " |      Finalizes this graph, making it read-only.\n",
      " |      \n",
      " |      After calling `g.finalize()`, no new operations can be added to\n",
      " |      `g`.  This method is used to ensure that no operations are added\n",
      " |      to a graph when it is shared between multiple threads, for example\n",
      " |      when using a `tf.compat.v1.train.QueueRunner`.\n",
      " |  \n",
      " |  get_all_collection_keys(self)\n",
      " |      Returns a list of collections used in this graph.\n",
      " |  \n",
      " |  get_collection(self, name, scope=None)\n",
      " |      Returns a list of values in the collection with the given `name`.\n",
      " |      \n",
      " |      This is different from `get_collection_ref()` which always returns the\n",
      " |      actual collection list if it exists in that it returns a new list each time\n",
      " |      it is called.\n",
      " |      \n",
      " |      Args:\n",
      " |        name: The key for the collection. For example, the `GraphKeys` class\n",
      " |          contains many standard names for collections.\n",
      " |        scope: (Optional.) A string. If supplied, the resulting list is filtered\n",
      " |          to include only items whose `name` attribute matches `scope` using\n",
      " |          `re.match`. Items without a `name` attribute are never returned if a\n",
      " |          scope is supplied. The choice of `re.match` means that a `scope` without\n",
      " |          special tokens filters by prefix.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The list of values in the collection with the given `name`, or\n",
      " |        an empty list if no value has been added to that collection. The\n",
      " |        list contains the values in the order under which they were\n",
      " |        collected.\n",
      " |  \n",
      " |  get_collection_ref(self, name)\n",
      " |      Returns a list of values in the collection with the given `name`.\n",
      " |      \n",
      " |      If the collection exists, this returns the list itself, which can\n",
      " |      be modified in place to change the collection.  If the collection does\n",
      " |      not exist, it is created as an empty list and the list is returned.\n",
      " |      \n",
      " |      This is different from `get_collection()` which always returns a copy of\n",
      " |      the collection list if it exists and never creates an empty collection.\n",
      " |      \n",
      " |      Args:\n",
      " |        name: The key for the collection. For example, the `GraphKeys` class\n",
      " |          contains many standard names for collections.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The list of values in the collection with the given `name`, or an empty\n",
      " |        list if no value has been added to that collection.\n",
      " |  \n",
      " |  get_name_scope(self)\n",
      " |      Returns the current name scope.\n",
      " |      \n",
      " |      For example:\n",
      " |      \n",
      " |      ```python\n",
      " |      with tf.name_scope('scope1'):\n",
      " |        with tf.name_scope('scope2'):\n",
      " |          print(tf.compat.v1.get_default_graph().get_name_scope())\n",
      " |      ```\n",
      " |      would print the string `scope1/scope2`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A string representing the current name scope.\n",
      " |  \n",
      " |  get_operation_by_name(self, name)\n",
      " |      Returns the `Operation` with the given `name`.\n",
      " |      \n",
      " |      This method may be called concurrently from multiple threads.\n",
      " |      \n",
      " |      Args:\n",
      " |        name: The name of the `Operation` to return.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The `Operation` with the given `name`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If `name` is not a string.\n",
      " |        KeyError: If `name` does not correspond to an operation in this graph.\n",
      " |  \n",
      " |  get_operations(self)\n",
      " |      Return the list of operations in the graph.\n",
      " |      \n",
      " |      You can modify the operations in place, but modifications\n",
      " |      to the list such as inserts/delete have no effect on the\n",
      " |      list of operations known to the graph.\n",
      " |      \n",
      " |      This method may be called concurrently from multiple threads.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of Operations.\n",
      " |  \n",
      " |  get_tensor_by_name(self, name)\n",
      " |      Returns the `Tensor` with the given `name`.\n",
      " |      \n",
      " |      This method may be called concurrently from multiple threads.\n",
      " |      \n",
      " |      Args:\n",
      " |        name: The name of the `Tensor` to return.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The `Tensor` with the given `name`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If `name` is not a string.\n",
      " |        KeyError: If `name` does not correspond to a tensor in this graph.\n",
      " |  \n",
      " |  gradient_override_map(self, op_type_map)\n",
      " |      EXPERIMENTAL: A context manager for overriding gradient functions.\n",
      " |      \n",
      " |      This context manager can be used to override the gradient function\n",
      " |      that will be used for ops within the scope of the context.\n",
      " |      \n",
      " |      For example:\n",
      " |      \n",
      " |      ```python\n",
      " |      @tf.RegisterGradient(\"CustomSquare\")\n",
      " |      def _custom_square_grad(op, grad):\n",
      " |        # ...\n",
      " |      \n",
      " |      with tf.Graph().as_default() as g:\n",
      " |        c = tf.constant(5.0)\n",
      " |        s_1 = tf.square(c)  # Uses the default gradient for tf.square.\n",
      " |        with g.gradient_override_map({\"Square\": \"CustomSquare\"}):\n",
      " |          s_2 = tf.square(s_2)  # Uses _custom_square_grad to compute the\n",
      " |                                # gradient of s_2.\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        op_type_map: A dictionary mapping op type strings to alternative op type\n",
      " |          strings.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A context manager that sets the alternative op type to be used for one\n",
      " |        or more ops created in that context.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If `op_type_map` is not a dictionary mapping strings to\n",
      " |          strings.\n",
      " |  \n",
      " |  is_feedable(self, tensor)\n",
      " |      Returns `True` if and only if `tensor` is feedable.\n",
      " |  \n",
      " |  is_fetchable(self, tensor_or_op)\n",
      " |      Returns `True` if and only if `tensor_or_op` is fetchable.\n",
      " |  \n",
      " |  name_scope(self, name)\n",
      " |      Returns a context manager that creates hierarchical names for operations.\n",
      " |      \n",
      " |      A graph maintains a stack of name scopes. A `with name_scope(...):`\n",
      " |      statement pushes a new name onto the stack for the lifetime of the context.\n",
      " |      \n",
      " |      The `name` argument will be interpreted as follows:\n",
      " |      \n",
      " |      * A string (not ending with '/') will create a new name scope, in which\n",
      " |        `name` is appended to the prefix of all operations created in the\n",
      " |        context. If `name` has been used before, it will be made unique by\n",
      " |        calling `self.unique_name(name)`.\n",
      " |      * A scope previously captured from a `with g.name_scope(...) as\n",
      " |        scope:` statement will be treated as an \"absolute\" name scope, which\n",
      " |        makes it possible to re-enter existing scopes.\n",
      " |      * A value of `None` or the empty string will reset the current name scope\n",
      " |        to the top-level (empty) name scope.\n",
      " |      \n",
      " |      For example:\n",
      " |      \n",
      " |      ```python\n",
      " |      with tf.Graph().as_default() as g:\n",
      " |        c = tf.constant(5.0, name=\"c\")\n",
      " |        assert c.op.name == \"c\"\n",
      " |        c_1 = tf.constant(6.0, name=\"c\")\n",
      " |        assert c_1.op.name == \"c_1\"\n",
      " |      \n",
      " |        # Creates a scope called \"nested\"\n",
      " |        with g.name_scope(\"nested\") as scope:\n",
      " |          nested_c = tf.constant(10.0, name=\"c\")\n",
      " |          assert nested_c.op.name == \"nested/c\"\n",
      " |      \n",
      " |          # Creates a nested scope called \"inner\".\n",
      " |          with g.name_scope(\"inner\"):\n",
      " |            nested_inner_c = tf.constant(20.0, name=\"c\")\n",
      " |            assert nested_inner_c.op.name == \"nested/inner/c\"\n",
      " |      \n",
      " |          # Create a nested scope called \"inner_1\".\n",
      " |          with g.name_scope(\"inner\"):\n",
      " |            nested_inner_1_c = tf.constant(30.0, name=\"c\")\n",
      " |            assert nested_inner_1_c.op.name == \"nested/inner_1/c\"\n",
      " |      \n",
      " |            # Treats `scope` as an absolute name scope, and\n",
      " |            # switches to the \"nested/\" scope.\n",
      " |            with g.name_scope(scope):\n",
      " |              nested_d = tf.constant(40.0, name=\"d\")\n",
      " |              assert nested_d.op.name == \"nested/d\"\n",
      " |      \n",
      " |              with g.name_scope(\"\"):\n",
      " |                e = tf.constant(50.0, name=\"e\")\n",
      " |                assert e.op.name == \"e\"\n",
      " |      ```\n",
      " |      \n",
      " |      The name of the scope itself can be captured by `with\n",
      " |      g.name_scope(...) as scope:`, which stores the name of the scope\n",
      " |      in the variable `scope`. This value can be used to name an\n",
      " |      operation that represents the overall result of executing the ops\n",
      " |      in a scope. For example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.constant(...)\n",
      " |      with g.name_scope('my_layer') as scope:\n",
      " |        weights = tf.Variable(..., name=\"weights\")\n",
      " |        biases = tf.Variable(..., name=\"biases\")\n",
      " |        affine = tf.matmul(inputs, weights) + biases\n",
      " |        output = tf.nn.relu(affine, name=scope)\n",
      " |      ```\n",
      " |      \n",
      " |      NOTE: This constructor validates the given `name`. Valid scope\n",
      " |      names match one of the following regular expressions:\n",
      " |      \n",
      " |          [A-Za-z0-9.][A-Za-z0-9_.\\-/]* (for scopes at the root)\n",
      " |          [A-Za-z0-9_.\\-/]* (for other scopes)\n",
      " |      \n",
      " |      Args:\n",
      " |        name: A name for the scope.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A context manager that installs `name` as a new name scope.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If `name` is not a valid scope name, according to the rules\n",
      " |          above.\n",
      " |  \n",
      " |  prevent_feeding(self, tensor)\n",
      " |      Marks the given `tensor` as unfeedable in this graph.\n",
      " |  \n",
      " |  prevent_fetching(self, op)\n",
      " |      Marks the given `op` as unfetchable in this graph.\n",
      " |  \n",
      " |  switch_to_thread_local(self)\n",
      " |      Make device, colocation and dependencies stacks thread-local.\n",
      " |      \n",
      " |      Device, colocation and dependencies stacks are not thread-local be default.\n",
      " |      If multiple threads access them, then the state is shared.  This means that\n",
      " |      one thread may affect the behavior of another thread.\n",
      " |      \n",
      " |      After this method is called, the stacks become thread-local.  If multiple\n",
      " |      threads access them, then the state is not shared.  Each thread uses its own\n",
      " |      value; a thread doesn't affect other threads by mutating such a stack.\n",
      " |      \n",
      " |      The initial value for every thread's stack is set to the current value\n",
      " |      of the stack when `switch_to_thread_local()` was first called.\n",
      " |  \n",
      " |  unique_name(self, name, mark_as_used=True)\n",
      " |      Return a unique operation name for `name`.\n",
      " |      \n",
      " |      Note: You rarely need to call `unique_name()` directly.  Most of\n",
      " |      the time you just need to create `with g.name_scope()` blocks to\n",
      " |      generate structured names.\n",
      " |      \n",
      " |      `unique_name` is used to generate structured names, separated by\n",
      " |      `\"/\"`, to help identify operations when debugging a graph.\n",
      " |      Operation names are displayed in error messages reported by the\n",
      " |      TensorFlow runtime, and in various visualization tools such as\n",
      " |      TensorBoard.\n",
      " |      \n",
      " |      If `mark_as_used` is set to `True`, which is the default, a new\n",
      " |      unique name is created and marked as in use. If it's set to `False`,\n",
      " |      the unique name is returned without actually being marked as used.\n",
      " |      This is useful when the caller simply wants to know what the name\n",
      " |      to be created will be.\n",
      " |      \n",
      " |      Args:\n",
      " |        name: The name for an operation.\n",
      " |        mark_as_used: Whether to mark this name as being used.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A string to be passed to `create_op()` that will be used\n",
      " |        to name the operation being created.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  building_function\n",
      " |      Returns True iff this graph represents a function.\n",
      " |  \n",
      " |  collections\n",
      " |      Returns the names of the collections known to this graph.\n",
      " |  \n",
      " |  finalized\n",
      " |      True if this graph has been finalized.\n",
      " |  \n",
      " |  graph_def_versions\n",
      " |      The GraphDef version information of this graph.\n",
      " |      \n",
      " |      For details on the meaning of each version, see\n",
      " |      [`GraphDef`](https://www.tensorflow.org/code/tensorflow/core/framework/graph.proto).\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `VersionDef`.\n",
      " |  \n",
      " |  version\n",
      " |      Returns a version number that increases as ops are added to the graph.\n",
      " |      \n",
      " |      Note that this is unrelated to the\n",
      " |      `tf.Graph.graph_def_versions`.\n",
      " |      \n",
      " |      Returns:\n",
      " |         An integer version that increases as ops are added to the graph.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  seed\n",
      " |      The graph-level random seed of this graph.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.Graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX.proto.graph_pb2 import GraphDef\n",
    "from tensorboardX.proto.node_def_pb2 import NodeDef\n",
    "from tensorboardX.proto import event_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = []\n",
    "reductions = vw.get_enabled_reductions()\n",
    "\n",
    "for ind, layer in enumerate(reductions):\n",
    "    if ind > 0:\n",
    "        nodes.append(NodeDef(name=layer, op='op', input=[reductions[ind-1]]))\n",
    "    else:\n",
    "        nodes.append(NodeDef(name=layer, op='op'))\n",
    "g = GraphDef(node=nodes)\n",
    "\n",
    "event = event_pb2.Event(graph_def=g.SerializeToString())\n",
    "file_writer._get_file_writer().add_event(event)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gd', 'scorer', 'csoaa_ldf', 'cb_adf', 'shared_feature_merger', 'cb_to_cbadf']\n",
      "node {\n",
      "  name: \"gd\"\n",
      "  op: \"op\"\n",
      "}\n",
      "node {\n",
      "  name: \"scorer\"\n",
      "  op: \"op\"\n",
      "  input: \"gd\"\n",
      "}\n",
      "node {\n",
      "  name: \"csoaa_ldf\"\n",
      "  op: \"op\"\n",
      "  input: \"scorer\"\n",
      "}\n",
      "node {\n",
      "  name: \"cb_adf\"\n",
      "  op: \"op\"\n",
      "  input: \"csoaa_ldf\"\n",
      "}\n",
      "node {\n",
      "  name: \"shared_feature_merger\"\n",
      "  op: \"op\"\n",
      "  input: \"cb_adf\"\n",
      "}\n",
      "node {\n",
      "  name: \"cb_to_cbadf\"\n",
      "  op: \"op\"\n",
      "  input: \"shared_feature_merger\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_writer._get_file_writer().flush()\n",
    "# file_writer.add_scalar('ss', 5000, 0)\n",
    "# file_writer.add_scalar('ss', 50, 1)\n",
    "\n",
    "print(reductions)\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on wrapper_descriptor:\n",
      "\n",
      "__init__(self, /, *args, **kwargs)\n",
      "    Initialize self.  See help(type(self)) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(GraphDef.__init__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class NodeDef in module tensorboardX.proto.node_def_pb2:\n",
      "\n",
      "class NodeDef(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      " |  A ProtocolMessage\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      NodeDef\n",
      " |      google.protobuf.pyext._message.CMessage\n",
      " |      google.protobuf.message.Message\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  attr\n",
      " |      Field tensorboardX.NodeDef.attr\n",
      " |  \n",
      " |  device\n",
      " |      Field tensorboardX.NodeDef.device\n",
      " |  \n",
      " |  input\n",
      " |      Field tensorboardX.NodeDef.input\n",
      " |  \n",
      " |  name\n",
      " |      Field tensorboardX.NodeDef.name\n",
      " |  \n",
      " |  op\n",
      " |      Field tensorboardX.NodeDef.op\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  AttrEntry = <class 'tensorboardX.proto.node_def_pb2.AttrEntry'>\n",
      " |      A ProtocolMessage\n",
      " |  \n",
      " |  DESCRIPTOR = <google.protobuf.pyext._message.MessageDescriptor object>\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from google.protobuf.pyext._message.CMessage:\n",
      " |  \n",
      " |  ByteSize(...)\n",
      " |      Returns the size of the message in bytes.\n",
      " |  \n",
      " |  Clear(...)\n",
      " |      Clears the message.\n",
      " |  \n",
      " |  ClearExtension(...)\n",
      " |      Clears a message field.\n",
      " |  \n",
      " |  ClearField(...)\n",
      " |      Clears a message field.\n",
      " |  \n",
      " |  CopyFrom(...)\n",
      " |      Copies a protocol message into the current message.\n",
      " |  \n",
      " |  DiscardUnknownFields(...)\n",
      " |      Discards the unknown fields.\n",
      " |  \n",
      " |  FindInitializationErrors(...)\n",
      " |      Finds unset required fields.\n",
      " |  \n",
      " |  HasExtension(...)\n",
      " |      Checks if a message field is set.\n",
      " |  \n",
      " |  HasField(...)\n",
      " |      Checks if a message field is set.\n",
      " |  \n",
      " |  IsInitialized(...)\n",
      " |      Checks if all required fields of a protocol message are set.\n",
      " |  \n",
      " |  ListFields(...)\n",
      " |      Lists all set fields of a message.\n",
      " |  \n",
      " |  MergeFrom(...)\n",
      " |      Merges a protocol message into the current message.\n",
      " |  \n",
      " |  MergeFromString(...)\n",
      " |      Merges a serialized message into the current message.\n",
      " |  \n",
      " |  ParseFromString(...)\n",
      " |      Parses a serialized message into the current message.\n",
      " |  \n",
      " |  SerializePartialToString(...)\n",
      " |      Serializes the message to a string, even if it isn't initialized.\n",
      " |  \n",
      " |  SerializeToString(...)\n",
      " |      Serializes the message to a string, only for initialized messages.\n",
      " |  \n",
      " |  SetInParent(...)\n",
      " |      Sets the has bit of the given field in its parent message.\n",
      " |  \n",
      " |  UnknownFields(...)\n",
      " |      Parse unknown field set\n",
      " |  \n",
      " |  WhichOneof(...)\n",
      " |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      " |  \n",
      " |  __deepcopy__(...)\n",
      " |      Makes a deep copy of the class.\n",
      " |  \n",
      " |  __eq__(self, value, /)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __ge__(self, value, /)\n",
      " |      Return self>=value.\n",
      " |  \n",
      " |  __getattribute__(self, name, /)\n",
      " |      Return getattr(self, name).\n",
      " |  \n",
      " |  __gt__(self, value, /)\n",
      " |      Return self>value.\n",
      " |  \n",
      " |  __init__(self, /, *args, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __le__(self, value, /)\n",
      " |      Return self<=value.\n",
      " |  \n",
      " |  __lt__(self, value, /)\n",
      " |      Return self<value.\n",
      " |  \n",
      " |  __ne__(self, value, /)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  __repr__(self, /)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __str__(self, /)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  __unicode__(...)\n",
      " |      Outputs a unicode representation of the message.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from google.protobuf.pyext._message.CMessage:\n",
      " |  \n",
      " |  FromString(...) from google.protobuf.pyext.cpp_message.GeneratedProtocolMessageType\n",
      " |      Creates new method instance from given serialized data.\n",
      " |  \n",
      " |  RegisterExtension(...) from google.protobuf.pyext.cpp_message.GeneratedProtocolMessageType\n",
      " |      Registers an extension with the current message.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from google.protobuf.pyext._message.CMessage:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from google.protobuf.pyext._message.MessageMeta\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from google.protobuf.pyext._message.CMessage:\n",
      " |  \n",
      " |  Extensions\n",
      " |      Extension dict\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from google.protobuf.pyext._message.CMessage:\n",
      " |  \n",
      " |  __hash__ = None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from google.protobuf.message.Message:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |      Support the pickle protocol.\n",
      " |  \n",
      " |  __reduce__(self)\n",
      " |      Helper for pickle.\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |      Support the pickle protocol.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(NodeDef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method add_onnx_graph in module tensorboardX.writer:\n",
      "\n",
      "add_onnx_graph(onnx_model_file) method of tensorboardX.writer.SummaryWriter instance\n",
      "    Add onnx graph to TensorBoard.\n",
      "    \n",
      "    Args:\n",
      "        onnx_model_file (string): The path to the onnx model.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(file_writer.add_onnx_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
