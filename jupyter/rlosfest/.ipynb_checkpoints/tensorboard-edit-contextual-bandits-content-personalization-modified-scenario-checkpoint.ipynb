{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vowpalwabbit import pyvw\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VW tries to minimize loss/cost, therefore we will pass cost as -reward\n",
    "USER_LIKED_ARTICLE = -1.0\n",
    "USER_DISLIKED_ARTICLE = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modified Second Scenario\n",
    "\n",
    "Let's Modify the second scenario in the tutorial. We will introduce many more cost functions and then after that a cost function which gives noisy data and after that compare performance of different exploration algorithms using visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cost(context,action):\n",
    "    if context['user'] == \"Tom\":\n",
    "        if context['time_of_day'] == \"morning\" and action == 'politics':\n",
    "            return USER_LIKED_ARTICLE\n",
    "        elif context['time_of_day'] == \"afternoon\" and action == 'music':\n",
    "            return USER_LIKED_ARTICLE\n",
    "        else:\n",
    "            return USER_DISLIKED_ARTICLE\n",
    "    \n",
    "    elif context['user'] == \"Anna\":\n",
    "        if context['time_of_day'] == \"morning\" and action == 'sports':\n",
    "            return USER_LIKED_ARTICLE\n",
    "        elif context['time_of_day'] == \"afternoon\" and action == 'politics':\n",
    "            return USER_LIKED_ARTICLE\n",
    "        else:\n",
    "            return USER_DISLIKED_ARTICLE\n",
    "        \n",
    "\n",
    "\n",
    "def get_cost_new1(context,action):\n",
    "    if context['user'] == \"Tom\":\n",
    "        if context['time_of_day'] == \"morning\" and action == 'politics':\n",
    "            return USER_LIKED_ARTICLE\n",
    "        elif context['time_of_day'] == \"afternoon\" and action == 'sports':\n",
    "            return USER_LIKED_ARTICLE\n",
    "        else:\n",
    "            return USER_DISLIKED_ARTICLE\n",
    "    elif context['user'] == \"Anna\":\n",
    "        if context['time_of_day'] == \"morning\" and action == 'sports':\n",
    "            return USER_LIKED_ARTICLE\n",
    "        elif context['time_of_day'] == \"afternoon\" and action == 'sports':\n",
    "            return USER_LIKED_ARTICLE\n",
    "        else:\n",
    "            return USER_DISLIKED_ARTICLE        \n",
    "        \n",
    "# SECOND MODIFIED SCENARIO \n",
    "\n",
    "def get_cost_new2(context,action):\n",
    "    if context['user'] == \"Tom\":\n",
    "        if context['time_of_day'] == \"morning\" and action == 'food':\n",
    "            return USER_LIKED_ARTICLE\n",
    "        elif context['time_of_day'] == \"afternoon\" and action == 'food':\n",
    "            return USER_LIKED_ARTICLE\n",
    "        else:\n",
    "            return USER_DISLIKED_ARTICLE\n",
    "    elif context['user'] == \"Anna\":\n",
    "        if context['time_of_day'] == \"morning\" and action == 'music':\n",
    "            return USER_LIKED_ARTICLE\n",
    "        elif context['time_of_day'] == \"afternoon\" and action == 'politics':\n",
    "            return USER_LIKED_ARTICLE\n",
    "        else:\n",
    "            return USER_DISLIKED_ARTICLE\n",
    "        \n",
    "def get_cost_new3(context,action):\n",
    "    if context['user'] == \"Tom\":\n",
    "        if context['time_of_day'] == \"morning\" and action == 'health':\n",
    "            return USER_LIKED_ARTICLE\n",
    "        elif context['time_of_day'] == \"afternoon\" and action == 'food':\n",
    "            return USER_LIKED_ARTICLE\n",
    "        else:\n",
    "            return USER_DISLIKED_ARTICLE\n",
    "    elif context['user'] == \"Anna\":\n",
    "        if context['time_of_day'] == \"morning\" and action == 'food':\n",
    "            return USER_LIKED_ARTICLE\n",
    "        elif context['time_of_day'] == \"afternoon\" and action == 'food':\n",
    "            return USER_LIKED_ARTICLE\n",
    "        else:\n",
    "            return USER_DISLIKED_ARTICLE    \n",
    "        \n",
    "def get_cost_new4(context,action):\n",
    "    if context['user'] == \"Tom\":\n",
    "        if context['time_of_day'] == \"morning\" and action == 'music':\n",
    "            return USER_LIKED_ARTICLE\n",
    "        elif context['time_of_day'] == \"afternoon\" and action == 'health':\n",
    "            return USER_LIKED_ARTICLE\n",
    "        else:\n",
    "            return USER_DISLIKED_ARTICLE\n",
    "    elif context['user'] == \"Anna\":\n",
    "        if context['time_of_day'] == \"morning\" and action == 'health':\n",
    "            return USER_LIKED_ARTICLE\n",
    "        elif context['time_of_day'] == \"afternoon\" and action == 'camping':\n",
    "            return USER_LIKED_ARTICLE\n",
    "        else:\n",
    "            return USER_DISLIKED_ARTICLE        \n",
    "        \n",
    "def get_cost_new5(context,action):\n",
    "    if context['user'] == \"Tom\":\n",
    "        if context['time_of_day'] == \"morning\" and action == 'finance':\n",
    "            return USER_LIKED_ARTICLE\n",
    "        elif context['time_of_day'] == \"afternoon\" and action == 'politics':\n",
    "            return USER_LIKED_ARTICLE\n",
    "        else:\n",
    "            return USER_DISLIKED_ARTICLE\n",
    "    elif context['user'] == \"Anna\":\n",
    "        if context['time_of_day'] == \"morning\" and action == 'sports':\n",
    "            return USER_LIKED_ARTICLE\n",
    "        elif context['time_of_day'] == \"afternoon\" and action == 'health':\n",
    "            return USER_LIKED_ARTICLE\n",
    "        else:\n",
    "            return USER_DISLIKED_ARTICLE\n",
    "        \n",
    "        \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's make reward function to produce Noise now\n",
    "\n",
    "Designing a suitable reward function plays a critical role in building reinforcement learning models for real-world applications. Ideally, one would want to customize reward functions to achieve application-specific goals. In practice, however, it is difficult to design a reward function that produces credible rewards in the presence of noise. This is because the **output from any reward function is subject to multiple kinds of randomness in the presence of noise**.\n",
    "But as we are simulating so we make a cost function (reward function) which gives us output that is subject to randomness so in this way we will be able to add noise to reward distribution. This is one of the simplest ways in case of our simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cost_noise(context,action):\n",
    "    if context['user'] == \"Tom\":\n",
    "        if context['time_of_day'] == \"morning\" and action == random.choice(actions):\n",
    "            return USER_LIKED_ARTICLE\n",
    "        elif context['time_of_day'] == \"afternoon\" and action == random.choice(actions):\n",
    "            return USER_LIKED_ARTICLE\n",
    "        else:\n",
    "            return USER_DISLIKED_ARTICLE\n",
    "    elif context['user'] == \"Anna\":\n",
    "        if context['time_of_day'] == \"morning\" and action == random.choice(actions):\n",
    "            return USER_LIKED_ARTICLE\n",
    "        elif context['time_of_day'] == \"afternoon\" and action == random.choice(actions):\n",
    "            return USER_LIKED_ARTICLE\n",
    "        else:\n",
    "            return USER_DISLIKED_ARTICLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function modifies (context, action, cost, probability) to VW friendly format\n",
    "def to_vw_example_format(context, actions, cb_label = None):\n",
    "    if cb_label is not None:\n",
    "        chosen_action, cost, prob = cb_label\n",
    "    \n",
    "    example_string = \"\"\n",
    "    example_string += \"shared |User user={} time_of_day={}\\n\".format(context[\"user\"], context[\"time_of_day\"])\n",
    "    \n",
    "    for action in actions:\n",
    "        if cb_label is not None and action == chosen_action:\n",
    "            example_string += \"0:{}:{} \".format(cost, prob)\n",
    "        example_string += \"|Action article={} \\n\".format(action)\n",
    "    \n",
    "    #Strip the last newline\n",
    "    return example_string[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_custom_pmf(pmf):\n",
    "    total = sum(pmf)\n",
    "    scale = 1 / total\n",
    "#     print(total, scale)\n",
    "    pmf = [x * scale for x in pmf]\n",
    "#     print(pmf)\n",
    "    draw = random.random()\n",
    "    sum_prob = 0.0\n",
    "    \n",
    "    for index, prob in enumerate(pmf):\n",
    "        sum_prob += prob\n",
    "        if(sum_prob > draw):\n",
    "            return index, prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the context and actions into the text format needed.\n",
    "# Pass this example to Vowpal Wabbit and get the PMF output.\n",
    "# Sample this PMF to get the article to show.\n",
    "# Return the chosen article and the probability of choosing it.â€¯\n",
    "# Note: We need the probability when we learn from this example.\n",
    "\n",
    "def get_action(vw, context, actions):\n",
    "    vw_text_example = to_vw_example_format(context,actions)\n",
    "    \n",
    "    pmf = vw.predict(vw_text_example)\n",
    "    \n",
    "    chosen_action_index, prob = sample_custom_pmf(pmf)\n",
    "    \n",
    "    return actions[chosen_action_index], prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = ['Tom', 'Anna']\n",
    "times_of_day = ['morning', 'afternoon']\n",
    "actions = [\"politics\", \"sports\", \"music\", \"food\", \"finance\", \"health\", \"camping\"]\n",
    "\n",
    "def choose_user(users):\n",
    "    return random.choice(users)\n",
    "\n",
    "def choose_time_of_day(times_of_day):\n",
    "    return random.choice(times_of_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ctr(num_iterations, ctr):\n",
    "    plt.plot(range(1,num_iterations+1), ctr)\n",
    "    plt.xlabel('num_iterations', fontsize=14)\n",
    "    plt.ylabel('ctr', fontsize=14)\n",
    "    plt.ylim([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation_multiple_cost_functions(vw, num_iterations, users, times_of_day, actions, cost_functions, do_learn = True):\n",
    "    logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    file_writer = tf.summary.create_file_writer(logdir + \"/ctr\")\n",
    "    file_writer.set_as_default()    \n",
    "    \n",
    "    cost_sum = 0.\n",
    "    ctr = []\n",
    "\n",
    "    start_counter = 1\n",
    "    end_counter = start_counter + num_iterations\n",
    "    for cost_function in cost_functions:\n",
    "        for i in range(start_counter, end_counter):\n",
    "            # 1. in each simulation choose a user\n",
    "            user = choose_user(users)\n",
    "            # 2. choose time of day for a given user\n",
    "            time_of_day = choose_time_of_day(times_of_day)\n",
    "\n",
    "            # Construct context based on chosen user and time of day\n",
    "            context = {'user': user, 'time_of_day': time_of_day}\n",
    "\n",
    "            # 3. Use the get_action function we defined earlier\n",
    "            action, prob = get_action(vw, context, actions)\n",
    "\n",
    "            # 4. Get cost of the action we chose\n",
    "            cost = cost_function(context, action)\n",
    "            cost_sum += cost\n",
    "\n",
    "            if do_learn:\n",
    "                # 5. Inform VW of what happened so we can learn from it\n",
    "                vw_format = vw.parse(to_vw_example_format(context, actions, (action, cost, prob)),pyvw.vw.lContextualBandit)\n",
    "                # 6. Learn\n",
    "                vw.learn(vw_format)\n",
    "\n",
    "            # We negate this so that on the plot instead of minimizing cost, we are maximizing reward\n",
    "            ctr.append(-1*cost_sum/i)\n",
    "            tf.summary.scalar('ctr', data=(-1*cost_sum/i), step=i)\n",
    "            \n",
    "        start_counter = end_counter\n",
    "        end_counter = start_counter + num_iterations\n",
    "\n",
    "    file_writer.close()\n",
    "    return ctr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datetime' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-c76f56e29245>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtotal_iterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_iterations_per_cost_func\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost_functions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mctr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_simulation_multiple_cost_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iterations_per_cost_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimes_of_day\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_functions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mplot_ctr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_iterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-072ab1c2977c>\u001b[0m in \u001b[0;36mrun_simulation_multiple_cost_functions\u001b[0;34m(vw, num_iterations, users, times_of_day, actions, cost_functions, do_learn)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun_simulation_multiple_cost_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimes_of_day\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_functions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_learn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mlogdir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"logs/scalars/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%Y%m%d-%H%M%S\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mfile_writer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_file_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogdir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/ctr\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mfile_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_as_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'datetime' is not defined"
     ]
    }
   ],
   "source": [
    "# With learning\n",
    "# use first reward function initially and then switch to other reward functions\n",
    "\n",
    "# Instantiate learner in VW\n",
    "vw = pyvw.vw(\"--cb_explore_adf -q UA --quiet --epsilon 0.2\")\n",
    "\n",
    "num_iterations_per_cost_func = 5000\n",
    "cost_functions = [get_cost, get_cost_new1, get_cost_new2, get_cost_new3, get_cost_new4, get_cost_new5]\n",
    "total_iterations = num_iterations_per_cost_func * len(cost_functions)\n",
    "\n",
    "ctr = run_simulation_multiple_cost_functions(vw, num_iterations_per_cost_func, users, times_of_day, actions, cost_functions)\n",
    "\n",
    "plot_ctr(total_iterations, ctr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Now Use Reward Function which adds Noise to Reward Distribution\n",
    "\n",
    "We would now change the cost function with respect to time which produces noise and add noise to our reward distribution (CTR). We can experiment with different ways to change cost functions with time but let's try simple one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With learning\n",
    "# use first reward function initially and then switch to noise and other reward function\n",
    "\n",
    "# Instantiate learner in VW\n",
    "vw = pyvw.vw(\"--cb_explore_adf -q UA --quiet --epsilon 0.2\")\n",
    "\n",
    "num_iterations_per_cost_func = 5000\n",
    "cost_functions = [get_cost, get_cost_noise, get_cost_new1, get_cost_noise, get_cost_new2, get_cost_noise, get_cost_new3, get_cost_noise, get_cost_new4, get_cost_noise, get_cost_new5]\n",
    "total_iterations = num_iterations_per_cost_func * len(cost_functions)\n",
    "\n",
    "ctr_epsilon = run_simulation_multiple_cost_functions(vw, num_iterations_per_cost_func, users, times_of_day, actions, cost_functions)\n",
    "\n",
    "plot_ctr(total_iterations, ctr_epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation with Different Exploration Algorithms\n",
    "\n",
    "Let's try using different exploration strategies and then visualize the performances. We would use:\n",
    "Explore-First Strategy\n",
    "Bagging\n",
    "Softmax\n",
    "RND   all as per the documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use first reward function initially and then switch to noise and other reward function\n",
    "\n",
    "# Instantiate learner in VW\n",
    "vw = pyvw.vw(\"--cb_explore_adf -q UA --quiet --first 7\")  # Explore-first\n",
    "\n",
    "# num_iterations_per_cost_func = 5000\n",
    "# cost_functions = [get_cost, get_cost_noise, get_cost_new1, get_cost_noise, get_cost_new2, get_cost_noise, get_cost_new3, get_cost_noise, get_cost_new4, get_cost_noise, get_cost_new5]\n",
    "# total_iterations = num_iterations_per_cost_func * len(cost_functions)\n",
    "\n",
    "ctr_first = run_simulation_multiple_cost_functions(vw, num_iterations_per_cost_func, users, times_of_day, actions, cost_functions)\n",
    "\n",
    "plot_ctr(total_iterations, ctr_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use first reward function initially and then switch to noise and other reward function\n",
    "\n",
    "# Instantiate learner in VW\n",
    "vw = pyvw.vw(\"--cb_explore_adf -q UA --quiet --bag 7\")\n",
    "\n",
    "# num_iterations_per_cost_func = 5000\n",
    "# cost_functions = [get_cost, get_cost_noise, get_cost_new1, get_cost_noise, get_cost_new2, get_cost_noise, get_cost_new3, get_cost_noise, get_cost_new4, get_cost_noise, get_cost_new5]\n",
    "# total_iterations = num_iterations_per_cost_func * len(cost_functions)\n",
    "\n",
    "ctr_bag = run_simulation_multiple_cost_functions(vw, num_iterations_per_cost_func, users, times_of_day, actions, cost_functions)\n",
    "\n",
    "plot_ctr(total_iterations, ctr_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# use first reward function initially and then switch to noise and other reward function\n",
    "\n",
    "# Instantiate learner in VW\n",
    "vw = pyvw.vw(\"--cb_explore_adf -q UA --quiet --softmax lambda 7\")\n",
    "\n",
    "# num_iterations_per_cost_func = 5000\n",
    "# cost_functions = [get_cost, get_cost_noise, get_cost_new1, get_cost_noise, get_cost_new2, get_cost_noise, get_cost_new3, get_cost_noise, get_cost_new4, get_cost_noise, get_cost_new5]\n",
    "# total_iterations = num_iterations_per_cost_func * len(cost_functions)\n",
    "\n",
    "ctr_soft = run_simulation_multiple_cost_functions(vw, num_iterations_per_cost_func, users, times_of_day, actions, cost_functions)\n",
    "\n",
    "plot_ctr(total_iterations, ctr_soft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use first reward function initially and then switch to noise and other reward function\n",
    "\n",
    "# Instantiate learner in VW\n",
    "vw = pyvw.vw(\"--cb_explore_adf -q UA --quiet --rnd 3 --epsilon 0.02\")\n",
    "\n",
    "# num_iterations_per_cost_func = 5000\n",
    "# cost_functions = [get_cost, get_cost_noise, get_cost_new1, get_cost_noise, get_cost_new2, get_cost_noise, get_cost_new3, get_cost_noise, get_cost_new4, get_cost_noise, get_cost_new5]\n",
    "# total_iterations = num_iterations_per_cost_func * len(cost_functions)\n",
    "\n",
    "ctr_rnd = run_simulation_multiple_cost_functions(vw, num_iterations_per_cost_func, users, times_of_day, actions, cost_functions)\n",
    "\n",
    "plot_ctr(total_iterations, ctr_rnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_iterations = range(1, total_iterations+1)\n",
    "font_size = 16\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.plot(num_of_iterations, ctr_epsilon, label='Epsilon greedy', color='orange')\n",
    "plt.plot(num_of_iterations, ctr_first, label='Explore First', color='blue')\n",
    "plt.plot(num_of_iterations, ctr_bag, label='Bagging Explorer', color='purple')\n",
    "plt.plot(num_of_iterations, ctr_soft, label='Softmax Explorer', color='violet')\n",
    "plt.plot(num_of_iterations, ctr_rnd, label='RND Explorer', color='red')\n",
    "\n",
    "plt.xlabel('num_iterations', fontsize=font_size)\n",
    "plt.ylabel('ctr', fontsize=font_size)\n",
    "plt.title('Performance of Different Exploration Strategies')\n",
    "plt.ylim([0,1])\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "We have used different exploration algorithms here and each algorithm performs differently in so many ways than other algorithms. RND Exploration is most like better performer than Epsilon greedy but it can be tuned further which could give us great results even in the presence of noise as many Reinforcement Learning algorithms perform poor due to noisy data. Explore First and Bagging after a peak or so start declining in performance which shows that due to noise they were unable to learn effectively. Softmax Explorer on the other hand looked like an algorithm that didn't learn, maybe it can be improved by finding out the better hyperparameters. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
