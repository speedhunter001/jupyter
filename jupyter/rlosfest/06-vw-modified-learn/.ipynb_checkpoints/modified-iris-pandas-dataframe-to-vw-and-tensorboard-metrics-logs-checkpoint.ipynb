{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from vowpalwabbit import pyvw\n",
    "from vowpalwabbit.DFtoVW import (\n",
    "    DFtoVW,\n",
    "    Feature,\n",
    "    MulticlassLabel,\n",
    "    MultiLabel,\n",
    "    Namespace,\n",
    "    SimpleLabel,\n",
    ")\n",
    "import tensorboardX as tx\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             150 non-null    int64  \n",
      " 1   SepalLengthCm  150 non-null    float64\n",
      " 2   SepalWidthCm   150 non-null    float64\n",
      " 3   PetalLengthCm  150 non-null    float64\n",
      " 4   PetalWidthCm   150 non-null    float64\n",
      " 5   Species        150 non-null    object \n",
      "dtypes: float64(4), int64(1), object(1)\n",
      "memory usage: 7.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  Species\n",
       "0   1            5.1           3.5            1.4           0.2        1\n",
       "1   2            4.9           3.0            1.4           0.2        1\n",
       "2   3            4.7           3.2            1.3           0.2        1\n",
       "3   4            4.6           3.1            1.5           0.2        1\n",
       "4   5            5.0           3.6            1.4           0.2        1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting \"Species\" categorical column to integer\n",
    "def categorical_to_int(specie):\n",
    "    if specie == 'Iris-setosa':\n",
    "        return 1\n",
    "    elif specie == 'Iris-versicolor':\n",
    "        return 2\n",
    "    elif specie == 'Iris-virginica':\n",
    "        return 3\n",
    "    \n",
    "df['Species'] = df['Species'].apply(categorical_to_int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = \"Species\"\n",
    "# features = [Feature(col) for col in df.columns if col != target_col]  # target column not part of Features\n",
    "features = [Feature(col) for col in df.columns if col != target_col and col != 'Id']  # 'Id' column also not part of Features along with target col\n",
    "label = MulticlassLabel(label=target_col)  # target column is a multi class label column\n",
    "tag = 'Id'\n",
    "\n",
    "df_to_vw = DFtoVW(df=df, features=features, label=label, tag=tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vw formatted strings: 150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1 1| SepalLengthCm:5.1 SepalWidthCm:3.5 PetalLengthCm:1.4 PetalWidthCm:0.2',\n",
       " '1 2| SepalLengthCm:4.9 SepalWidthCm:3.0 PetalLengthCm:1.4 PetalWidthCm:0.2',\n",
       " '1 3| SepalLengthCm:4.7 SepalWidthCm:3.2 PetalLengthCm:1.3 PetalWidthCm:0.2',\n",
       " '1 4| SepalLengthCm:4.6 SepalWidthCm:3.1 PetalLengthCm:1.5 PetalWidthCm:0.2',\n",
       " '1 5| SepalLengthCm:5.0 SepalWidthCm:3.6 PetalLengthCm:1.4 PetalWidthCm:0.2',\n",
       " '1 6| SepalLengthCm:5.4 SepalWidthCm:3.9 PetalLengthCm:1.7 PetalWidthCm:0.4',\n",
       " '1 7| SepalLengthCm:4.6 SepalWidthCm:3.4 PetalLengthCm:1.4 PetalWidthCm:0.3',\n",
       " '1 8| SepalLengthCm:5.0 SepalWidthCm:3.4 PetalLengthCm:1.5 PetalWidthCm:0.2',\n",
       " '1 9| SepalLengthCm:4.4 SepalWidthCm:2.9 PetalLengthCm:1.4 PetalWidthCm:0.2',\n",
       " '1 10| SepalLengthCm:4.9 SepalWidthCm:3.1 PetalLengthCm:1.5 PetalWidthCm:0.1',\n",
       " '1 11| SepalLengthCm:5.4 SepalWidthCm:3.7 PetalLengthCm:1.5 PetalWidthCm:0.2',\n",
       " '1 12| SepalLengthCm:4.8 SepalWidthCm:3.4 PetalLengthCm:1.6 PetalWidthCm:0.2',\n",
       " '1 13| SepalLengthCm:4.8 SepalWidthCm:3.0 PetalLengthCm:1.4 PetalWidthCm:0.1',\n",
       " '1 14| SepalLengthCm:4.3 SepalWidthCm:3.0 PetalLengthCm:1.1 PetalWidthCm:0.1',\n",
       " '1 15| SepalLengthCm:5.8 SepalWidthCm:4.0 PetalLengthCm:1.2 PetalWidthCm:0.2',\n",
       " '1 16| SepalLengthCm:5.7 SepalWidthCm:4.4 PetalLengthCm:1.5 PetalWidthCm:0.4',\n",
       " '1 17| SepalLengthCm:5.4 SepalWidthCm:3.9 PetalLengthCm:1.3 PetalWidthCm:0.4',\n",
       " '1 18| SepalLengthCm:5.1 SepalWidthCm:3.5 PetalLengthCm:1.4 PetalWidthCm:0.3',\n",
       " '1 19| SepalLengthCm:5.7 SepalWidthCm:3.8 PetalLengthCm:1.7 PetalWidthCm:0.3',\n",
       " '1 20| SepalLengthCm:5.1 SepalWidthCm:3.8 PetalLengthCm:1.5 PetalWidthCm:0.3',\n",
       " '1 21| SepalLengthCm:5.4 SepalWidthCm:3.4 PetalLengthCm:1.7 PetalWidthCm:0.2',\n",
       " '1 22| SepalLengthCm:5.1 SepalWidthCm:3.7 PetalLengthCm:1.5 PetalWidthCm:0.4',\n",
       " '1 23| SepalLengthCm:4.6 SepalWidthCm:3.6 PetalLengthCm:1.0 PetalWidthCm:0.2',\n",
       " '1 24| SepalLengthCm:5.1 SepalWidthCm:3.3 PetalLengthCm:1.7 PetalWidthCm:0.5',\n",
       " '1 25| SepalLengthCm:4.8 SepalWidthCm:3.4 PetalLengthCm:1.9 PetalWidthCm:0.2',\n",
       " '1 26| SepalLengthCm:5.0 SepalWidthCm:3.0 PetalLengthCm:1.6 PetalWidthCm:0.2',\n",
       " '1 27| SepalLengthCm:5.0 SepalWidthCm:3.4 PetalLengthCm:1.6 PetalWidthCm:0.4',\n",
       " '1 28| SepalLengthCm:5.2 SepalWidthCm:3.5 PetalLengthCm:1.5 PetalWidthCm:0.2',\n",
       " '1 29| SepalLengthCm:5.2 SepalWidthCm:3.4 PetalLengthCm:1.4 PetalWidthCm:0.2',\n",
       " '1 30| SepalLengthCm:4.7 SepalWidthCm:3.2 PetalLengthCm:1.6 PetalWidthCm:0.2',\n",
       " '1 31| SepalLengthCm:4.8 SepalWidthCm:3.1 PetalLengthCm:1.6 PetalWidthCm:0.2',\n",
       " '1 32| SepalLengthCm:5.4 SepalWidthCm:3.4 PetalLengthCm:1.5 PetalWidthCm:0.4',\n",
       " '1 33| SepalLengthCm:5.2 SepalWidthCm:4.1 PetalLengthCm:1.5 PetalWidthCm:0.1',\n",
       " '1 34| SepalLengthCm:5.5 SepalWidthCm:4.2 PetalLengthCm:1.4 PetalWidthCm:0.2',\n",
       " '1 35| SepalLengthCm:4.9 SepalWidthCm:3.1 PetalLengthCm:1.5 PetalWidthCm:0.1',\n",
       " '1 36| SepalLengthCm:5.0 SepalWidthCm:3.2 PetalLengthCm:1.2 PetalWidthCm:0.2',\n",
       " '1 37| SepalLengthCm:5.5 SepalWidthCm:3.5 PetalLengthCm:1.3 PetalWidthCm:0.2',\n",
       " '1 38| SepalLengthCm:4.9 SepalWidthCm:3.1 PetalLengthCm:1.5 PetalWidthCm:0.1',\n",
       " '1 39| SepalLengthCm:4.4 SepalWidthCm:3.0 PetalLengthCm:1.3 PetalWidthCm:0.2',\n",
       " '1 40| SepalLengthCm:5.1 SepalWidthCm:3.4 PetalLengthCm:1.5 PetalWidthCm:0.2',\n",
       " '1 41| SepalLengthCm:5.0 SepalWidthCm:3.5 PetalLengthCm:1.3 PetalWidthCm:0.3',\n",
       " '1 42| SepalLengthCm:4.5 SepalWidthCm:2.3 PetalLengthCm:1.3 PetalWidthCm:0.3',\n",
       " '1 43| SepalLengthCm:4.4 SepalWidthCm:3.2 PetalLengthCm:1.3 PetalWidthCm:0.2',\n",
       " '1 44| SepalLengthCm:5.0 SepalWidthCm:3.5 PetalLengthCm:1.6 PetalWidthCm:0.6',\n",
       " '1 45| SepalLengthCm:5.1 SepalWidthCm:3.8 PetalLengthCm:1.9 PetalWidthCm:0.4',\n",
       " '1 46| SepalLengthCm:4.8 SepalWidthCm:3.0 PetalLengthCm:1.4 PetalWidthCm:0.3',\n",
       " '1 47| SepalLengthCm:5.1 SepalWidthCm:3.8 PetalLengthCm:1.6 PetalWidthCm:0.2',\n",
       " '1 48| SepalLengthCm:4.6 SepalWidthCm:3.2 PetalLengthCm:1.4 PetalWidthCm:0.2',\n",
       " '1 49| SepalLengthCm:5.3 SepalWidthCm:3.7 PetalLengthCm:1.5 PetalWidthCm:0.2',\n",
       " '1 50| SepalLengthCm:5.0 SepalWidthCm:3.3 PetalLengthCm:1.4 PetalWidthCm:0.2',\n",
       " '2 51| SepalLengthCm:7.0 SepalWidthCm:3.2 PetalLengthCm:4.7 PetalWidthCm:1.4',\n",
       " '2 52| SepalLengthCm:6.4 SepalWidthCm:3.2 PetalLengthCm:4.5 PetalWidthCm:1.5',\n",
       " '2 53| SepalLengthCm:6.9 SepalWidthCm:3.1 PetalLengthCm:4.9 PetalWidthCm:1.5',\n",
       " '2 54| SepalLengthCm:5.5 SepalWidthCm:2.3 PetalLengthCm:4.0 PetalWidthCm:1.3',\n",
       " '2 55| SepalLengthCm:6.5 SepalWidthCm:2.8 PetalLengthCm:4.6 PetalWidthCm:1.5',\n",
       " '2 56| SepalLengthCm:5.7 SepalWidthCm:2.8 PetalLengthCm:4.5 PetalWidthCm:1.3',\n",
       " '2 57| SepalLengthCm:6.3 SepalWidthCm:3.3 PetalLengthCm:4.7 PetalWidthCm:1.6',\n",
       " '2 58| SepalLengthCm:4.9 SepalWidthCm:2.4 PetalLengthCm:3.3 PetalWidthCm:1.0',\n",
       " '2 59| SepalLengthCm:6.6 SepalWidthCm:2.9 PetalLengthCm:4.6 PetalWidthCm:1.3',\n",
       " '2 60| SepalLengthCm:5.2 SepalWidthCm:2.7 PetalLengthCm:3.9 PetalWidthCm:1.4',\n",
       " '2 61| SepalLengthCm:5.0 SepalWidthCm:2.0 PetalLengthCm:3.5 PetalWidthCm:1.0',\n",
       " '2 62| SepalLengthCm:5.9 SepalWidthCm:3.0 PetalLengthCm:4.2 PetalWidthCm:1.5',\n",
       " '2 63| SepalLengthCm:6.0 SepalWidthCm:2.2 PetalLengthCm:4.0 PetalWidthCm:1.0',\n",
       " '2 64| SepalLengthCm:6.1 SepalWidthCm:2.9 PetalLengthCm:4.7 PetalWidthCm:1.4',\n",
       " '2 65| SepalLengthCm:5.6 SepalWidthCm:2.9 PetalLengthCm:3.6 PetalWidthCm:1.3',\n",
       " '2 66| SepalLengthCm:6.7 SepalWidthCm:3.1 PetalLengthCm:4.4 PetalWidthCm:1.4',\n",
       " '2 67| SepalLengthCm:5.6 SepalWidthCm:3.0 PetalLengthCm:4.5 PetalWidthCm:1.5',\n",
       " '2 68| SepalLengthCm:5.8 SepalWidthCm:2.7 PetalLengthCm:4.1 PetalWidthCm:1.0',\n",
       " '2 69| SepalLengthCm:6.2 SepalWidthCm:2.2 PetalLengthCm:4.5 PetalWidthCm:1.5',\n",
       " '2 70| SepalLengthCm:5.6 SepalWidthCm:2.5 PetalLengthCm:3.9 PetalWidthCm:1.1',\n",
       " '2 71| SepalLengthCm:5.9 SepalWidthCm:3.2 PetalLengthCm:4.8 PetalWidthCm:1.8',\n",
       " '2 72| SepalLengthCm:6.1 SepalWidthCm:2.8 PetalLengthCm:4.0 PetalWidthCm:1.3',\n",
       " '2 73| SepalLengthCm:6.3 SepalWidthCm:2.5 PetalLengthCm:4.9 PetalWidthCm:1.5',\n",
       " '2 74| SepalLengthCm:6.1 SepalWidthCm:2.8 PetalLengthCm:4.7 PetalWidthCm:1.2',\n",
       " '2 75| SepalLengthCm:6.4 SepalWidthCm:2.9 PetalLengthCm:4.3 PetalWidthCm:1.3',\n",
       " '2 76| SepalLengthCm:6.6 SepalWidthCm:3.0 PetalLengthCm:4.4 PetalWidthCm:1.4',\n",
       " '2 77| SepalLengthCm:6.8 SepalWidthCm:2.8 PetalLengthCm:4.8 PetalWidthCm:1.4',\n",
       " '2 78| SepalLengthCm:6.7 SepalWidthCm:3.0 PetalLengthCm:5.0 PetalWidthCm:1.7',\n",
       " '2 79| SepalLengthCm:6.0 SepalWidthCm:2.9 PetalLengthCm:4.5 PetalWidthCm:1.5',\n",
       " '2 80| SepalLengthCm:5.7 SepalWidthCm:2.6 PetalLengthCm:3.5 PetalWidthCm:1.0',\n",
       " '2 81| SepalLengthCm:5.5 SepalWidthCm:2.4 PetalLengthCm:3.8 PetalWidthCm:1.1',\n",
       " '2 82| SepalLengthCm:5.5 SepalWidthCm:2.4 PetalLengthCm:3.7 PetalWidthCm:1.0',\n",
       " '2 83| SepalLengthCm:5.8 SepalWidthCm:2.7 PetalLengthCm:3.9 PetalWidthCm:1.2',\n",
       " '2 84| SepalLengthCm:6.0 SepalWidthCm:2.7 PetalLengthCm:5.1 PetalWidthCm:1.6',\n",
       " '2 85| SepalLengthCm:5.4 SepalWidthCm:3.0 PetalLengthCm:4.5 PetalWidthCm:1.5',\n",
       " '2 86| SepalLengthCm:6.0 SepalWidthCm:3.4 PetalLengthCm:4.5 PetalWidthCm:1.6',\n",
       " '2 87| SepalLengthCm:6.7 SepalWidthCm:3.1 PetalLengthCm:4.7 PetalWidthCm:1.5',\n",
       " '2 88| SepalLengthCm:6.3 SepalWidthCm:2.3 PetalLengthCm:4.4 PetalWidthCm:1.3',\n",
       " '2 89| SepalLengthCm:5.6 SepalWidthCm:3.0 PetalLengthCm:4.1 PetalWidthCm:1.3',\n",
       " '2 90| SepalLengthCm:5.5 SepalWidthCm:2.5 PetalLengthCm:4.0 PetalWidthCm:1.3',\n",
       " '2 91| SepalLengthCm:5.5 SepalWidthCm:2.6 PetalLengthCm:4.4 PetalWidthCm:1.2',\n",
       " '2 92| SepalLengthCm:6.1 SepalWidthCm:3.0 PetalLengthCm:4.6 PetalWidthCm:1.4',\n",
       " '2 93| SepalLengthCm:5.8 SepalWidthCm:2.6 PetalLengthCm:4.0 PetalWidthCm:1.2',\n",
       " '2 94| SepalLengthCm:5.0 SepalWidthCm:2.3 PetalLengthCm:3.3 PetalWidthCm:1.0',\n",
       " '2 95| SepalLengthCm:5.6 SepalWidthCm:2.7 PetalLengthCm:4.2 PetalWidthCm:1.3',\n",
       " '2 96| SepalLengthCm:5.7 SepalWidthCm:3.0 PetalLengthCm:4.2 PetalWidthCm:1.2',\n",
       " '2 97| SepalLengthCm:5.7 SepalWidthCm:2.9 PetalLengthCm:4.2 PetalWidthCm:1.3',\n",
       " '2 98| SepalLengthCm:6.2 SepalWidthCm:2.9 PetalLengthCm:4.3 PetalWidthCm:1.3',\n",
       " '2 99| SepalLengthCm:5.1 SepalWidthCm:2.5 PetalLengthCm:3.0 PetalWidthCm:1.1',\n",
       " '2 100| SepalLengthCm:5.7 SepalWidthCm:2.8 PetalLengthCm:4.1 PetalWidthCm:1.3',\n",
       " '3 101| SepalLengthCm:6.3 SepalWidthCm:3.3 PetalLengthCm:6.0 PetalWidthCm:2.5',\n",
       " '3 102| SepalLengthCm:5.8 SepalWidthCm:2.7 PetalLengthCm:5.1 PetalWidthCm:1.9',\n",
       " '3 103| SepalLengthCm:7.1 SepalWidthCm:3.0 PetalLengthCm:5.9 PetalWidthCm:2.1',\n",
       " '3 104| SepalLengthCm:6.3 SepalWidthCm:2.9 PetalLengthCm:5.6 PetalWidthCm:1.8',\n",
       " '3 105| SepalLengthCm:6.5 SepalWidthCm:3.0 PetalLengthCm:5.8 PetalWidthCm:2.2',\n",
       " '3 106| SepalLengthCm:7.6 SepalWidthCm:3.0 PetalLengthCm:6.6 PetalWidthCm:2.1',\n",
       " '3 107| SepalLengthCm:4.9 SepalWidthCm:2.5 PetalLengthCm:4.5 PetalWidthCm:1.7',\n",
       " '3 108| SepalLengthCm:7.3 SepalWidthCm:2.9 PetalLengthCm:6.3 PetalWidthCm:1.8',\n",
       " '3 109| SepalLengthCm:6.7 SepalWidthCm:2.5 PetalLengthCm:5.8 PetalWidthCm:1.8',\n",
       " '3 110| SepalLengthCm:7.2 SepalWidthCm:3.6 PetalLengthCm:6.1 PetalWidthCm:2.5',\n",
       " '3 111| SepalLengthCm:6.5 SepalWidthCm:3.2 PetalLengthCm:5.1 PetalWidthCm:2.0',\n",
       " '3 112| SepalLengthCm:6.4 SepalWidthCm:2.7 PetalLengthCm:5.3 PetalWidthCm:1.9',\n",
       " '3 113| SepalLengthCm:6.8 SepalWidthCm:3.0 PetalLengthCm:5.5 PetalWidthCm:2.1',\n",
       " '3 114| SepalLengthCm:5.7 SepalWidthCm:2.5 PetalLengthCm:5.0 PetalWidthCm:2.0',\n",
       " '3 115| SepalLengthCm:5.8 SepalWidthCm:2.8 PetalLengthCm:5.1 PetalWidthCm:2.4',\n",
       " '3 116| SepalLengthCm:6.4 SepalWidthCm:3.2 PetalLengthCm:5.3 PetalWidthCm:2.3',\n",
       " '3 117| SepalLengthCm:6.5 SepalWidthCm:3.0 PetalLengthCm:5.5 PetalWidthCm:1.8',\n",
       " '3 118| SepalLengthCm:7.7 SepalWidthCm:3.8 PetalLengthCm:6.7 PetalWidthCm:2.2',\n",
       " '3 119| SepalLengthCm:7.7 SepalWidthCm:2.6 PetalLengthCm:6.9 PetalWidthCm:2.3',\n",
       " '3 120| SepalLengthCm:6.0 SepalWidthCm:2.2 PetalLengthCm:5.0 PetalWidthCm:1.5',\n",
       " '3 121| SepalLengthCm:6.9 SepalWidthCm:3.2 PetalLengthCm:5.7 PetalWidthCm:2.3',\n",
       " '3 122| SepalLengthCm:5.6 SepalWidthCm:2.8 PetalLengthCm:4.9 PetalWidthCm:2.0',\n",
       " '3 123| SepalLengthCm:7.7 SepalWidthCm:2.8 PetalLengthCm:6.7 PetalWidthCm:2.0',\n",
       " '3 124| SepalLengthCm:6.3 SepalWidthCm:2.7 PetalLengthCm:4.9 PetalWidthCm:1.8',\n",
       " '3 125| SepalLengthCm:6.7 SepalWidthCm:3.3 PetalLengthCm:5.7 PetalWidthCm:2.1',\n",
       " '3 126| SepalLengthCm:7.2 SepalWidthCm:3.2 PetalLengthCm:6.0 PetalWidthCm:1.8',\n",
       " '3 127| SepalLengthCm:6.2 SepalWidthCm:2.8 PetalLengthCm:4.8 PetalWidthCm:1.8',\n",
       " '3 128| SepalLengthCm:6.1 SepalWidthCm:3.0 PetalLengthCm:4.9 PetalWidthCm:1.8',\n",
       " '3 129| SepalLengthCm:6.4 SepalWidthCm:2.8 PetalLengthCm:5.6 PetalWidthCm:2.1',\n",
       " '3 130| SepalLengthCm:7.2 SepalWidthCm:3.0 PetalLengthCm:5.8 PetalWidthCm:1.6',\n",
       " '3 131| SepalLengthCm:7.4 SepalWidthCm:2.8 PetalLengthCm:6.1 PetalWidthCm:1.9',\n",
       " '3 132| SepalLengthCm:7.9 SepalWidthCm:3.8 PetalLengthCm:6.4 PetalWidthCm:2.0',\n",
       " '3 133| SepalLengthCm:6.4 SepalWidthCm:2.8 PetalLengthCm:5.6 PetalWidthCm:2.2',\n",
       " '3 134| SepalLengthCm:6.3 SepalWidthCm:2.8 PetalLengthCm:5.1 PetalWidthCm:1.5',\n",
       " '3 135| SepalLengthCm:6.1 SepalWidthCm:2.6 PetalLengthCm:5.6 PetalWidthCm:1.4',\n",
       " '3 136| SepalLengthCm:7.7 SepalWidthCm:3.0 PetalLengthCm:6.1 PetalWidthCm:2.3',\n",
       " '3 137| SepalLengthCm:6.3 SepalWidthCm:3.4 PetalLengthCm:5.6 PetalWidthCm:2.4',\n",
       " '3 138| SepalLengthCm:6.4 SepalWidthCm:3.1 PetalLengthCm:5.5 PetalWidthCm:1.8',\n",
       " '3 139| SepalLengthCm:6.0 SepalWidthCm:3.0 PetalLengthCm:4.8 PetalWidthCm:1.8',\n",
       " '3 140| SepalLengthCm:6.9 SepalWidthCm:3.1 PetalLengthCm:5.4 PetalWidthCm:2.1',\n",
       " '3 141| SepalLengthCm:6.7 SepalWidthCm:3.1 PetalLengthCm:5.6 PetalWidthCm:2.4',\n",
       " '3 142| SepalLengthCm:6.9 SepalWidthCm:3.1 PetalLengthCm:5.1 PetalWidthCm:2.3',\n",
       " '3 143| SepalLengthCm:5.8 SepalWidthCm:2.7 PetalLengthCm:5.1 PetalWidthCm:1.9',\n",
       " '3 144| SepalLengthCm:6.8 SepalWidthCm:3.2 PetalLengthCm:5.9 PetalWidthCm:2.3',\n",
       " '3 145| SepalLengthCm:6.7 SepalWidthCm:3.3 PetalLengthCm:5.7 PetalWidthCm:2.5',\n",
       " '3 146| SepalLengthCm:6.7 SepalWidthCm:3.0 PetalLengthCm:5.2 PetalWidthCm:2.3',\n",
       " '3 147| SepalLengthCm:6.3 SepalWidthCm:2.5 PetalLengthCm:5.0 PetalWidthCm:1.9',\n",
       " '3 148| SepalLengthCm:6.5 SepalWidthCm:3.0 PetalLengthCm:5.2 PetalWidthCm:2.0',\n",
       " '3 149| SepalLengthCm:6.2 SepalWidthCm:3.4 PetalLengthCm:5.4 PetalWidthCm:2.3',\n",
       " '3 150| SepalLengthCm:5.9 SepalWidthCm:3.0 PetalLengthCm:5.1 PetalWidthCm:1.8']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vw_formatted_data = df_to_vw.convert_df()   # Converting dataframe to vw required string format\n",
    "print(\"Total vw formatted strings:\", len(vw_formatted_data))\n",
    "vw_formatted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(example, label_type):\n",
    "    switch_label_type = {\n",
    "        pyvw.vw.lDefault: None,\n",
    "        pyvw.vw.lBinary: example.get_simplelabel_label,\n",
    "        pyvw.vw.lMulticlass: example.get_multiclass_label,\n",
    "        pyvw.vw.lCostSensitive: example.get_costsensitive_class,\n",
    "        pyvw.vw.lContextualBandit: example.get_cbandits_class\n",
    "#         pyvw.vw.lConditionalContextualBandit:\n",
    "#         pyvw.vw.lSlates:\n",
    "#         pyvw.vw.lContinuous:\n",
    "    }\n",
    "    return switch_label_type[label_type]()\n",
    "\n",
    "def calculate_average_loss(sum_loss, weighted_examples):\n",
    "    try:\n",
    "        return sum_loss / weighted_examples\n",
    "    \n",
    "    except ZeroDivisionError:\n",
    "        return 0.\n",
    "\n",
    "def calculate_since_last(sum_loss_since_last, weighted_examples_since_last):\n",
    "    try:\n",
    "        return sum_loss_since_last / weighted_examples_since_last\n",
    "    \n",
    "    except ZeroDivisionError:\n",
    "        return 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vw = pyvw.vw('--oaa 3 -P 1')  # -oaa is One Agent All algo for multi class problem (seems supervised) -P 1 outputs metrics for each example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tfeatures: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tfeatures: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tfeatures: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tfeatures: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tfeatures: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tfeatures: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tfeatures: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tfeatures: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tfeatures: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tfeatures: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tfeatures: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tfeatures: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tfeatures: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tfeatures: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tfeatures: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tfeatures: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tfeatures: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tfeatures: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tfeatures: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tfeatures: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tfeatures: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tfeatures: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tfeatures: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tfeatures: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tfeatures: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tfeatures: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tfeatures: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tfeatures: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tfeatures: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tfeatures: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tfeatures: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tfeatures: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tfeatures: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tfeatures: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tfeatures: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tfeatures: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tfeatures: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tfeatures: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tfeatures: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tfeatures: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tfeatures: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tfeatures: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tfeatures: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tfeatures: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tfeatures: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tfeatures: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tfeatures: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tfeatures: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tfeatures: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tfeatures: 5\n",
      "average_loss:0.019608\tsince_last:1.000000\tlabel: 2\tprediction: 1\tfeatures: 5\n",
      "average_loss:0.038462\tsince_last:1.000000\tlabel: 2\tprediction: 1\tfeatures: 5\n",
      "average_loss:0.037736\tsince_last:0.000000\tlabel: 2\tprediction: 2\tfeatures: 5\n",
      "average_loss:0.037037\tsince_last:0.000000\tlabel: 2\tprediction: 2\tfeatures: 5\n",
      "average_loss:0.036364\tsince_last:0.000000\tlabel: 2\tprediction: 2\tfeatures: 5\n",
      "average_loss:0.035714\tsince_last:0.000000\tlabel: 2\tprediction: 2\tfeatures: 5\n",
      "average_loss:0.035088\tsince_last:0.000000\tlabel: 2\tprediction: 2\tfeatures: 5\n",
      "average_loss:0.034483\tsince_last:0.000000\tlabel: 2\tprediction: 2\tfeatures: 5\n",
      "average_loss:0.033898\tsince_last:0.000000\tlabel: 2\tprediction: 2\tfeatures: 5\n",
      "average_loss:0.033333\tsince_last:0.000000\tlabel: 2\tprediction: 2\tfeatures: 5\n",
      "average_loss:0.032787\tsince_last:0.000000\tlabel: 2\tprediction: 2\tfeatures: 5\n",
      "average_loss:0.032258\tsince_last:0.000000\tlabel: 2\tprediction: 2\tfeatures: 5\n",
      "average_loss:0.031746\tsince_last:0.000000\tlabel: 2\tprediction: 2\tfeatures: 5\n",
      "average_loss:0.031250\tsince_last:0.000000\tlabel: 2\tprediction: 2\tfeatures: 5\n",
      "average_loss:0.030769\tsince_last:0.000000\tlabel: 2\tprediction: 2\tfeatures: 5\n",
      "average_loss:0.030303\tsince_last:0.000000\tlabel: 2\tprediction: 2\tfeatures: 5\n",
      "average_loss:0.029851\tsince_last:0.000000\tlabel: 2\tprediction: 2\tfeatures: 5\n",
      "average_loss:0.029412\tsince_last:0.000000\tlabel: 2\tprediction: 2\tfeatures: 5\n",
      "average_loss:0.028986\tsince_last:0.000000\tlabel: 2\tprediction: 2\tfeatures: 5\n",
      "average_loss:0.028571\tsince_last:0.000000\tlabel: 2\tprediction: 2\tfeatures: 5\n",
      "average_loss:0.028169\tsince_last:0.000000\tlabel: 2\tprediction: 2\tfeatures: 5\n",
      "average_loss:0.027778\tsince_last:0.000000\tlabel: 2\tprediction: 2\tfeatures: 5\n",
      "average_loss:0.027397\tsince_last:0.000000\tlabel: 2\tprediction: 2\tfeatures: 5\n",
      "average_loss:0.027027\tsince_last:0.000000\tlabel: 2\tprediction: 2\tfeatures: 5\n",
      "average_loss:0.026667\tsince_last:0.000000\tlabel: 2\tprediction: 2\tfeatures: 5\n",
      "average_loss:0.026316\tsince_last:0.000000\tlabel: 2\tprediction: 2\tfeatures: 5\n",
      "average_loss:0.025974\tsince_last:0.000000\tlabel: 2\tprediction: 2\tfeatures: 5\n",
      "average_loss:0.025641\tsince_last:0.000000\tlabel: 2\tprediction: 2\tfeatures: 5\n",
      "average_loss:0.025316\tsince_last:0.000000\tlabel: 2\tprediction: 2\tfeatures: 5\n",
      "average_loss:0.025000\tsince_last:0.000000\tlabel: 2\tprediction: 2\tfeatures: 5\n",
      "average_loss:0.024691\tsince_last:0.000000\tlabel: 2\tprediction: 2\tfeatures: 5\n",
      "average_loss:0.024390\tsince_last:0.000000\tlabel: 2\tprediction: 2\tfeatures: 5\n",
      "average_loss:0.024096\tsince_last:0.000000\tlabel: 2\tprediction: 2\tfeatures: 5\n",
      "average_loss:0.023810\tsince_last:0.000000\tlabel: 2\tprediction: 2\tfeatures: 5\n",
      "average_loss:0.023529\tsince_last:0.000000\tlabel: 2\tprediction: 2\tfeatures: 5\n",
      "average_loss:0.023256\tsince_last:0.000000\tlabel: 2\tprediction: 2\tfeatures: 5\n",
      "average_loss:0.022989\tsince_last:0.000000\tlabel: 2\tprediction: 2\tfeatures: 5\n",
      "average_loss:0.022727\tsince_last:0.000000\tlabel: 2\tprediction: 2\tfeatures: 5\n",
      "average_loss:0.022472\tsince_last:0.000000\tlabel: 2\tprediction: 2\tfeatures: 5\n",
      "average_loss:0.022222\tsince_last:0.000000\tlabel: 2\tprediction: 2\tfeatures: 5\n",
      "average_loss:0.021978\tsince_last:0.000000\tlabel: 2\tprediction: 2\tfeatures: 5\n",
      "average_loss:0.021739\tsince_last:0.000000\tlabel: 2\tprediction: 2\tfeatures: 5\n",
      "average_loss:0.021505\tsince_last:0.000000\tlabel: 2\tprediction: 2\tfeatures: 5\n",
      "average_loss:0.021277\tsince_last:0.000000\tlabel: 2\tprediction: 2\tfeatures: 5\n",
      "average_loss:0.021053\tsince_last:0.000000\tlabel: 2\tprediction: 2\tfeatures: 5\n",
      "average_loss:0.020833\tsince_last:0.000000\tlabel: 2\tprediction: 2\tfeatures: 5\n",
      "average_loss:0.020619\tsince_last:0.000000\tlabel: 2\tprediction: 2\tfeatures: 5\n",
      "average_loss:0.020408\tsince_last:0.000000\tlabel: 2\tprediction: 2\tfeatures: 5\n",
      "average_loss:0.020202\tsince_last:0.000000\tlabel: 2\tprediction: 2\tfeatures: 5\n",
      "average_loss:0.020000\tsince_last:0.000000\tlabel: 2\tprediction: 2\tfeatures: 5\n",
      "average_loss:0.029703\tsince_last:1.000000\tlabel: 3\tprediction: 2\tfeatures: 5\n",
      "average_loss:0.039216\tsince_last:1.000000\tlabel: 3\tprediction: 2\tfeatures: 5\n",
      "average_loss:0.048544\tsince_last:1.000000\tlabel: 3\tprediction: 2\tfeatures: 5\n",
      "average_loss:0.048077\tsince_last:0.000000\tlabel: 3\tprediction: 3\tfeatures: 5\n",
      "average_loss:0.047619\tsince_last:0.000000\tlabel: 3\tprediction: 3\tfeatures: 5\n",
      "average_loss:0.047170\tsince_last:0.000000\tlabel: 3\tprediction: 3\tfeatures: 5\n",
      "average_loss:0.046729\tsince_last:0.000000\tlabel: 3\tprediction: 3\tfeatures: 5\n",
      "average_loss:0.046296\tsince_last:0.000000\tlabel: 3\tprediction: 3\tfeatures: 5\n",
      "average_loss:0.045872\tsince_last:0.000000\tlabel: 3\tprediction: 3\tfeatures: 5\n",
      "average_loss:0.045455\tsince_last:0.000000\tlabel: 3\tprediction: 3\tfeatures: 5\n",
      "average_loss:0.045045\tsince_last:0.000000\tlabel: 3\tprediction: 3\tfeatures: 5\n",
      "average_loss:0.044643\tsince_last:0.000000\tlabel: 3\tprediction: 3\tfeatures: 5\n",
      "average_loss:0.044248\tsince_last:0.000000\tlabel: 3\tprediction: 3\tfeatures: 5\n",
      "average_loss:0.043860\tsince_last:0.000000\tlabel: 3\tprediction: 3\tfeatures: 5\n",
      "average_loss:0.043478\tsince_last:0.000000\tlabel: 3\tprediction: 3\tfeatures: 5\n",
      "average_loss:0.043103\tsince_last:0.000000\tlabel: 3\tprediction: 3\tfeatures: 5\n",
      "average_loss:0.042735\tsince_last:0.000000\tlabel: 3\tprediction: 3\tfeatures: 5\n",
      "average_loss:0.042373\tsince_last:0.000000\tlabel: 3\tprediction: 3\tfeatures: 5\n",
      "average_loss:0.042017\tsince_last:0.000000\tlabel: 3\tprediction: 3\tfeatures: 5\n",
      "average_loss:0.041667\tsince_last:0.000000\tlabel: 3\tprediction: 3\tfeatures: 5\n",
      "average_loss:0.041322\tsince_last:0.000000\tlabel: 3\tprediction: 3\tfeatures: 5\n",
      "average_loss:0.040984\tsince_last:0.000000\tlabel: 3\tprediction: 3\tfeatures: 5\n",
      "average_loss:0.040650\tsince_last:0.000000\tlabel: 3\tprediction: 3\tfeatures: 5\n",
      "average_loss:0.040323\tsince_last:0.000000\tlabel: 3\tprediction: 3\tfeatures: 5\n",
      "average_loss:0.040000\tsince_last:0.000000\tlabel: 3\tprediction: 3\tfeatures: 5\n",
      "average_loss:0.039683\tsince_last:0.000000\tlabel: 3\tprediction: 3\tfeatures: 5\n",
      "average_loss:0.039370\tsince_last:0.000000\tlabel: 3\tprediction: 3\tfeatures: 5\n",
      "average_loss:0.039062\tsince_last:0.000000\tlabel: 3\tprediction: 3\tfeatures: 5\n",
      "average_loss:0.038760\tsince_last:0.000000\tlabel: 3\tprediction: 3\tfeatures: 5\n",
      "average_loss:0.038462\tsince_last:0.000000\tlabel: 3\tprediction: 3\tfeatures: 5\n",
      "average_loss:0.038168\tsince_last:0.000000\tlabel: 3\tprediction: 3\tfeatures: 5\n",
      "average_loss:0.037879\tsince_last:0.000000\tlabel: 3\tprediction: 3\tfeatures: 5\n",
      "average_loss:0.037594\tsince_last:0.000000\tlabel: 3\tprediction: 3\tfeatures: 5\n",
      "average_loss:0.037313\tsince_last:0.000000\tlabel: 3\tprediction: 3\tfeatures: 5\n",
      "average_loss:0.037037\tsince_last:0.000000\tlabel: 3\tprediction: 3\tfeatures: 5\n",
      "average_loss:0.036765\tsince_last:0.000000\tlabel: 3\tprediction: 3\tfeatures: 5\n",
      "average_loss:0.036496\tsince_last:0.000000\tlabel: 3\tprediction: 3\tfeatures: 5\n",
      "average_loss:0.036232\tsince_last:0.000000\tlabel: 3\tprediction: 3\tfeatures: 5\n",
      "average_loss:0.035971\tsince_last:0.000000\tlabel: 3\tprediction: 3\tfeatures: 5\n",
      "average_loss:0.035714\tsince_last:0.000000\tlabel: 3\tprediction: 3\tfeatures: 5\n",
      "average_loss:0.035461\tsince_last:0.000000\tlabel: 3\tprediction: 3\tfeatures: 5\n",
      "average_loss:0.035211\tsince_last:0.000000\tlabel: 3\tprediction: 3\tfeatures: 5\n",
      "average_loss:0.034965\tsince_last:0.000000\tlabel: 3\tprediction: 3\tfeatures: 5\n",
      "average_loss:0.034722\tsince_last:0.000000\tlabel: 3\tprediction: 3\tfeatures: 5\n",
      "average_loss:0.034483\tsince_last:0.000000\tlabel: 3\tprediction: 3\tfeatures: 5\n",
      "average_loss:0.034247\tsince_last:0.000000\tlabel: 3\tprediction: 3\tfeatures: 5\n",
      "average_loss:0.034014\tsince_last:0.000000\tlabel: 3\tprediction: 3\tfeatures: 5\n",
      "average_loss:0.033784\tsince_last:0.000000\tlabel: 3\tprediction: 3\tfeatures: 5\n",
      "average_loss:0.033557\tsince_last:0.000000\tlabel: 3\tprediction: 3\tfeatures: 5\n",
      "average_loss:0.033333\tsince_last:0.000000\tlabel: 3\tprediction: 3\tfeatures: 5\n"
     ]
    }
   ],
   "source": [
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")  # logs directory\n",
    "file_writer = tx.SummaryWriter(logdir+'/iris')   # creating file writer\n",
    "sum_loss = 0.\n",
    "weighted_examples = 0.\n",
    "\n",
    "if isinstance(vw_to_tensorboard, VWtoTensorboard):\n",
    "    file_writer = tx.SummaryWriter(vw_to_tensorboard.logdir)   # creating file writer\n",
    "\n",
    "sum_loss = 0.\n",
    "weighted_examples = 0.\n",
    "\n",
    "for iteration, vw_format in enumerate(self.vw_formatted_data):\n",
    "    example = self.vw.parse(vw_format)       # parse the string format, it returns an example object\n",
    "    self.vw.learn(example)                  # learn on example\n",
    "\n",
    "    label = pyvw.get_label(example, self.vw.get_label_type())\n",
    "    prediction = pyvw.get_prediction(example, self.vw.get_prediction_type())\n",
    "    num_features = example.get_feature_number()    \n",
    "\n",
    "    self.vw.finish_example(example)  # Any use of vw object should be done after this and use of example before this \n",
    "\n",
    "    if (print_metrics or vw_to_tensorboard):\n",
    "        sum_loss_since_last = self.vw.get_sum_loss() - sum_loss  # vw.get_sum_loss() return current sum loss, sum_loss variable right now holds sum loss of previous iteration\n",
    "        weighted_examples_since_last = self.vw.get_weighted_examples() - weighted_examples  # vw.get_weighted_examples() return current weighted examples(sum),  weighted_examples variable right now holds weighted examples of previous iteration\t\t        \n",
    "\n",
    "        sum_loss = self.vw.get_sum_loss()  # Now sum_loss no longer hold previous iteration's sum_loss\n",
    "        weighted_examples = self.vw.get_weighted_examples()  # Now weighted_examples no longer hold previous iteration's weighted examples\n",
    "\n",
    "        average_loss = (sum_loss / weighted_examples) if weighted_examples != 0  else 0.0\n",
    "        since_last = (sum_loss_since_last / weighted_examples_since_last) if weighted_examples_since_last != 0  else 0.0\n",
    "\n",
    "    if print_metrics:\n",
    "        self._print_metrics(average_loss, since_last, label, prediction, num_features)\n",
    "\n",
    "    if isinstance(vw_to_tensorboard, VWtoTensorboard):\n",
    "        file_writer.add_scalar('average_loss', average_loss, iteration)  # logging average_loss on each iteration\n",
    "        file_writer.add_scalar('since_last', since_last, iteration)   # logging since_last on each iteration\n",
    "    #     file_writer.add_scalar('label' , label, iteration)\n",
    "    #     file_writer.add_scalar('prediction', prediction, iteration)\n",
    "    #     file_writer.add_histogram('label-prediction', [label, prediction], iteration)\n",
    "    #     file_writer.add_histogram('label', label, iteration)\n",
    "    #     file_writer.add_histogram('prediction', prediction, iteration)\n",
    "        file_writer.add_scalar('num_features', num_features, iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")  # logs directory\n",
    "# file_writer = tx.SummaryWriter(logdir + \"/iris-train\")   # creating file writer\n",
    "# sum_loss = 0.\n",
    "# weighted_examples = 0.\n",
    "\n",
    "# for ind, iteration in zip(train.index, range(len(df))):\n",
    "#     vw_format = vw_formatted_data[ind]\n",
    "#     vw.learn(vw_format)\n",
    "    \n",
    "#     sum_loss_since_last = vw.get_sum_loss() - sum_loss   \n",
    "#     weighted_examples_since_last = vw.get_weighted_examples() - weighted_examples  \n",
    "        \n",
    "#     sum_loss= vw.get_sum_loss()\n",
    "#     weighted_examples = vw.get_weighted_examples()\n",
    "    \n",
    "#     average_loss = calculate_average_loss(sum_loss, weighted_examples)\n",
    "#     since_last = calculate_since_last(sum_loss_since_last, weighted_examples_since_last)\n",
    "\n",
    "#     print( 'average_loss:{:.6f}'.format(average_loss) , end='\\t')\n",
    "#     print('since_last:{:.6f}'.format(since_last))\n",
    "#     file_writer.add_scalar('average_loss', average_loss, iteration)\n",
    "#     file_writer.add_scalar('since_last', since_last, iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3\n",
      "1 3\n",
      "2 3\n",
      "2 3\n",
      "1 3\n",
      "2 3\n",
      "1 3\n",
      "3 3\n",
      "2 3\n",
      "3 3\n",
      "2 3\n",
      "2 3\n",
      "3 3\n",
      "1 3\n",
      "1 3\n"
     ]
    }
   ],
   "source": [
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")  # logs directory\n",
    "file_writer = tx.SummaryWriter(logdir + \"/test\")   # creating file writer\n",
    "\n",
    "for ind, iteration in zip(test.index, range(len(test))):\n",
    "    vw_format = vw_formatted_data[ind]\n",
    "    pipe_char_index = vw_format.index('|')\n",
    "    vw_format_predict = vw_format[pipe_char_index:]\n",
    "    \n",
    "    prediction = vw.predict(vw_format_predict)\n",
    "    print(vw_format[0], prediction)\n",
    "#     print(vw_format[0] == prediction)\n",
    "    if vw_format[0] == prediction:\n",
    "        is_correct = 1\n",
    "    else:\n",
    "        is_correct = 0\n",
    "    \n",
    "    file_writer.add_scalar('correct_prediction', is_correct, iteration)   #  scalar value of ctr in this iteration\n",
    "\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tnum_features: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tnum_features: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tnum_features: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tnum_features: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tnum_features: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tnum_features: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tnum_features: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tnum_features: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tnum_features: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tnum_features: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tnum_features: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tnum_features: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tnum_features: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tnum_features: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tnum_features: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tnum_features: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tnum_features: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tnum_features: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tnum_features: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tnum_features: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tnum_features: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tnum_features: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tnum_features: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tnum_features: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tnum_features: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tnum_features: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tnum_features: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tnum_features: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tnum_features: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tnum_features: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tnum_features: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tnum_features: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tnum_features: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tnum_features: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tnum_features: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tnum_features: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tnum_features: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tnum_features: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tnum_features: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tnum_features: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tnum_features: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tnum_features: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tnum_features: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tnum_features: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tnum_features: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tnum_features: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tnum_features: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tnum_features: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tnum_features: 5\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tnum_features: 5\n",
      "average_loss:0.019608\tsince_last:1.000000\tlabel: 2\tprediction: 1\tnum_features: 5\n",
      "average_loss:0.038462\tsince_last:1.000000\tlabel: 2\tprediction: 1\tnum_features: 5\n",
      "average_loss:0.037736\tsince_last:0.000000\tlabel: 2\tprediction: 2\tnum_features: 5\n",
      "average_loss:0.037037\tsince_last:0.000000\tlabel: 2\tprediction: 2\tnum_features: 5\n",
      "average_loss:0.036364\tsince_last:0.000000\tlabel: 2\tprediction: 2\tnum_features: 5\n",
      "average_loss:0.035714\tsince_last:0.000000\tlabel: 2\tprediction: 2\tnum_features: 5\n",
      "average_loss:0.035088\tsince_last:0.000000\tlabel: 2\tprediction: 2\tnum_features: 5\n",
      "average_loss:0.034483\tsince_last:0.000000\tlabel: 2\tprediction: 2\tnum_features: 5\n",
      "average_loss:0.033898\tsince_last:0.000000\tlabel: 2\tprediction: 2\tnum_features: 5\n",
      "average_loss:0.033333\tsince_last:0.000000\tlabel: 2\tprediction: 2\tnum_features: 5\n",
      "average_loss:0.032787\tsince_last:0.000000\tlabel: 2\tprediction: 2\tnum_features: 5\n",
      "average_loss:0.032258\tsince_last:0.000000\tlabel: 2\tprediction: 2\tnum_features: 5\n",
      "average_loss:0.031746\tsince_last:0.000000\tlabel: 2\tprediction: 2\tnum_features: 5\n",
      "average_loss:0.031250\tsince_last:0.000000\tlabel: 2\tprediction: 2\tnum_features: 5\n",
      "average_loss:0.030769\tsince_last:0.000000\tlabel: 2\tprediction: 2\tnum_features: 5\n",
      "average_loss:0.030303\tsince_last:0.000000\tlabel: 2\tprediction: 2\tnum_features: 5\n",
      "average_loss:0.029851\tsince_last:0.000000\tlabel: 2\tprediction: 2\tnum_features: 5\n",
      "average_loss:0.029412\tsince_last:0.000000\tlabel: 2\tprediction: 2\tnum_features: 5\n",
      "average_loss:0.028986\tsince_last:0.000000\tlabel: 2\tprediction: 2\tnum_features: 5\n",
      "average_loss:0.028571\tsince_last:0.000000\tlabel: 2\tprediction: 2\tnum_features: 5\n",
      "average_loss:0.028169\tsince_last:0.000000\tlabel: 2\tprediction: 2\tnum_features: 5\n",
      "average_loss:0.027778\tsince_last:0.000000\tlabel: 2\tprediction: 2\tnum_features: 5\n",
      "average_loss:0.027397\tsince_last:0.000000\tlabel: 2\tprediction: 2\tnum_features: 5\n",
      "average_loss:0.027027\tsince_last:0.000000\tlabel: 2\tprediction: 2\tnum_features: 5\n",
      "average_loss:0.026667\tsince_last:0.000000\tlabel: 2\tprediction: 2\tnum_features: 5\n",
      "average_loss:0.026316\tsince_last:0.000000\tlabel: 2\tprediction: 2\tnum_features: 5\n",
      "average_loss:0.025974\tsince_last:0.000000\tlabel: 2\tprediction: 2\tnum_features: 5\n",
      "average_loss:0.025641\tsince_last:0.000000\tlabel: 2\tprediction: 2\tnum_features: 5\n",
      "average_loss:0.025316\tsince_last:0.000000\tlabel: 2\tprediction: 2\tnum_features: 5\n",
      "average_loss:0.025000\tsince_last:0.000000\tlabel: 2\tprediction: 2\tnum_features: 5\n",
      "average_loss:0.024691\tsince_last:0.000000\tlabel: 2\tprediction: 2\tnum_features: 5\n",
      "average_loss:0.024390\tsince_last:0.000000\tlabel: 2\tprediction: 2\tnum_features: 5\n",
      "average_loss:0.024096\tsince_last:0.000000\tlabel: 2\tprediction: 2\tnum_features: 5\n",
      "average_loss:0.023810\tsince_last:0.000000\tlabel: 2\tprediction: 2\tnum_features: 5\n",
      "average_loss:0.023529\tsince_last:0.000000\tlabel: 2\tprediction: 2\tnum_features: 5\n",
      "average_loss:0.023256\tsince_last:0.000000\tlabel: 2\tprediction: 2\tnum_features: 5\n",
      "average_loss:0.022989\tsince_last:0.000000\tlabel: 2\tprediction: 2\tnum_features: 5\n",
      "average_loss:0.022727\tsince_last:0.000000\tlabel: 2\tprediction: 2\tnum_features: 5\n",
      "average_loss:0.022472\tsince_last:0.000000\tlabel: 2\tprediction: 2\tnum_features: 5\n",
      "average_loss:0.022222\tsince_last:0.000000\tlabel: 2\tprediction: 2\tnum_features: 5\n",
      "average_loss:0.021978\tsince_last:0.000000\tlabel: 2\tprediction: 2\tnum_features: 5\n",
      "average_loss:0.021739\tsince_last:0.000000\tlabel: 2\tprediction: 2\tnum_features: 5\n",
      "average_loss:0.021505\tsince_last:0.000000\tlabel: 2\tprediction: 2\tnum_features: 5\n",
      "average_loss:0.021277\tsince_last:0.000000\tlabel: 2\tprediction: 2\tnum_features: 5\n",
      "average_loss:0.021053\tsince_last:0.000000\tlabel: 2\tprediction: 2\tnum_features: 5\n",
      "average_loss:0.020833\tsince_last:0.000000\tlabel: 2\tprediction: 2\tnum_features: 5\n",
      "average_loss:0.020619\tsince_last:0.000000\tlabel: 2\tprediction: 2\tnum_features: 5\n",
      "average_loss:0.020408\tsince_last:0.000000\tlabel: 2\tprediction: 2\tnum_features: 5\n",
      "average_loss:0.020202\tsince_last:0.000000\tlabel: 2\tprediction: 2\tnum_features: 5\n",
      "average_loss:0.020000\tsince_last:0.000000\tlabel: 2\tprediction: 2\tnum_features: 5\n",
      "average_loss:0.029703\tsince_last:1.000000\tlabel: 3\tprediction: 2\tnum_features: 5\n",
      "average_loss:0.039216\tsince_last:1.000000\tlabel: 3\tprediction: 2\tnum_features: 5\n",
      "average_loss:0.048544\tsince_last:1.000000\tlabel: 3\tprediction: 2\tnum_features: 5\n",
      "average_loss:0.048077\tsince_last:0.000000\tlabel: 3\tprediction: 3\tnum_features: 5\n",
      "average_loss:0.047619\tsince_last:0.000000\tlabel: 3\tprediction: 3\tnum_features: 5\n",
      "average_loss:0.047170\tsince_last:0.000000\tlabel: 3\tprediction: 3\tnum_features: 5\n",
      "average_loss:0.046729\tsince_last:0.000000\tlabel: 3\tprediction: 3\tnum_features: 5\n",
      "average_loss:0.046296\tsince_last:0.000000\tlabel: 3\tprediction: 3\tnum_features: 5\n",
      "average_loss:0.045872\tsince_last:0.000000\tlabel: 3\tprediction: 3\tnum_features: 5\n",
      "average_loss:0.045455\tsince_last:0.000000\tlabel: 3\tprediction: 3\tnum_features: 5\n",
      "average_loss:0.045045\tsince_last:0.000000\tlabel: 3\tprediction: 3\tnum_features: 5\n",
      "average_loss:0.044643\tsince_last:0.000000\tlabel: 3\tprediction: 3\tnum_features: 5\n",
      "average_loss:0.044248\tsince_last:0.000000\tlabel: 3\tprediction: 3\tnum_features: 5\n",
      "average_loss:0.043860\tsince_last:0.000000\tlabel: 3\tprediction: 3\tnum_features: 5\n",
      "average_loss:0.043478\tsince_last:0.000000\tlabel: 3\tprediction: 3\tnum_features: 5\n",
      "average_loss:0.043103\tsince_last:0.000000\tlabel: 3\tprediction: 3\tnum_features: 5\n",
      "average_loss:0.042735\tsince_last:0.000000\tlabel: 3\tprediction: 3\tnum_features: 5\n",
      "average_loss:0.042373\tsince_last:0.000000\tlabel: 3\tprediction: 3\tnum_features: 5\n",
      "average_loss:0.042017\tsince_last:0.000000\tlabel: 3\tprediction: 3\tnum_features: 5\n",
      "average_loss:0.041667\tsince_last:0.000000\tlabel: 3\tprediction: 3\tnum_features: 5\n",
      "average_loss:0.041322\tsince_last:0.000000\tlabel: 3\tprediction: 3\tnum_features: 5\n",
      "average_loss:0.040984\tsince_last:0.000000\tlabel: 3\tprediction: 3\tnum_features: 5\n",
      "average_loss:0.040650\tsince_last:0.000000\tlabel: 3\tprediction: 3\tnum_features: 5\n",
      "average_loss:0.040323\tsince_last:0.000000\tlabel: 3\tprediction: 3\tnum_features: 5\n",
      "average_loss:0.040000\tsince_last:0.000000\tlabel: 3\tprediction: 3\tnum_features: 5\n",
      "average_loss:0.039683\tsince_last:0.000000\tlabel: 3\tprediction: 3\tnum_features: 5\n",
      "average_loss:0.039370\tsince_last:0.000000\tlabel: 3\tprediction: 3\tnum_features: 5\n",
      "average_loss:0.039062\tsince_last:0.000000\tlabel: 3\tprediction: 3\tnum_features: 5\n",
      "average_loss:0.038760\tsince_last:0.000000\tlabel: 3\tprediction: 3\tnum_features: 5\n",
      "average_loss:0.038462\tsince_last:0.000000\tlabel: 3\tprediction: 3\tnum_features: 5\n",
      "average_loss:0.038168\tsince_last:0.000000\tlabel: 3\tprediction: 3\tnum_features: 5\n",
      "average_loss:0.037879\tsince_last:0.000000\tlabel: 3\tprediction: 3\tnum_features: 5\n",
      "average_loss:0.037594\tsince_last:0.000000\tlabel: 3\tprediction: 3\tnum_features: 5\n",
      "average_loss:0.037313\tsince_last:0.000000\tlabel: 3\tprediction: 3\tnum_features: 5\n",
      "average_loss:0.037037\tsince_last:0.000000\tlabel: 3\tprediction: 3\tnum_features: 5\n",
      "average_loss:0.036765\tsince_last:0.000000\tlabel: 3\tprediction: 3\tnum_features: 5\n",
      "average_loss:0.036496\tsince_last:0.000000\tlabel: 3\tprediction: 3\tnum_features: 5\n",
      "average_loss:0.036232\tsince_last:0.000000\tlabel: 3\tprediction: 3\tnum_features: 5\n",
      "average_loss:0.035971\tsince_last:0.000000\tlabel: 3\tprediction: 3\tnum_features: 5\n",
      "average_loss:0.035714\tsince_last:0.000000\tlabel: 3\tprediction: 3\tnum_features: 5\n",
      "average_loss:0.035461\tsince_last:0.000000\tlabel: 3\tprediction: 3\tnum_features: 5\n",
      "average_loss:0.035211\tsince_last:0.000000\tlabel: 3\tprediction: 3\tnum_features: 5\n",
      "average_loss:0.034965\tsince_last:0.000000\tlabel: 3\tprediction: 3\tnum_features: 5\n",
      "average_loss:0.034722\tsince_last:0.000000\tlabel: 3\tprediction: 3\tnum_features: 5\n",
      "average_loss:0.034483\tsince_last:0.000000\tlabel: 3\tprediction: 3\tnum_features: 5\n",
      "average_loss:0.034247\tsince_last:0.000000\tlabel: 3\tprediction: 3\tnum_features: 5\n",
      "average_loss:0.034014\tsince_last:0.000000\tlabel: 3\tprediction: 3\tnum_features: 5\n",
      "average_loss:0.033784\tsince_last:0.000000\tlabel: 3\tprediction: 3\tnum_features: 5\n",
      "average_loss:0.033557\tsince_last:0.000000\tlabel: 3\tprediction: 3\tnum_features: 5\n",
      "average_loss:0.033333\tsince_last:0.000000\tlabel: 3\tprediction: 3\tnum_features: 5\n"
     ]
    }
   ],
   "source": [
    "from DFtoVWtoTensorboard import DFtoVWtoTensorboard\n",
    "to_tensorboard = DFtoVWtoTensorboard(df=df, df_to_vw=df_to_vw)\n",
    "\n",
    "vw2 = pyvw.vw('--oaa 3 -P 1')  # -oaa is One Agent All algo for multi class problem (seems supervised) -P 1 outputs metrics for each example\n",
    "to_tensorboard.fit(vw2, tensorboard=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simple = pd.DataFrame({\n",
    "        \"f1\": [1, 2, 3],\n",
    "        \"f2\": [1.2, 2.3, 3.4],\n",
    "        \"f3\": [0.2, 0.8, .01],\n",
    "        \"l\": [1, 2, 3],\n",
    "})\n",
    "\n",
    "label = MulticlassLabel(label=\"l\")\n",
    "features = [Feature(col) for col in [\"f1\", \"f2\", \"f3\"]]\n",
    "\n",
    "df_to_vw = DFtoVW(df=df_simple, label=label, features=features)\n",
    "vw = pyvw.vw('--oaa 3 -P 1')\n",
    "vw_formatted_data = df_to_vw.convert_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "average_loss:0.000000\tsince_last:0.000000\tlabel: 1\tprediction: 1\tfeatures: 4\n",
      "1 1\n",
      "average_loss:0.500000\tsince_last:1.000000\tlabel: 2\tprediction: 1\tfeatures: 4\n",
      "2 2\n",
      "average_loss:0.666667\tsince_last:1.000000\tlabel: 3\tprediction: 2\tfeatures: 4\n"
     ]
    }
   ],
   "source": [
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")  # logs directory\n",
    "file_writer = tx.SummaryWriter(logdir + \"/iris\")   # creating file writer\n",
    "sum_loss = 0.\n",
    "weighted_examples = 0.\n",
    "\n",
    "for ind, iteration in zip(df_simple.index, range(len(df_simple))):\n",
    "    print(ind, iteration)\n",
    "    vw_format = vw_formatted_data[ind]   # get the string format of specific example\n",
    "    example = vw.parse(vw_format) \n",
    "    vw.learn(example)\n",
    "\n",
    "    label = get_label(example, vw.get_label_type())\n",
    "    prediction = pyvw.get_prediction(example, vw.get_prediction_type())\n",
    "    features = example.get_feature_number()    \n",
    "\n",
    "    vw.finish_example(example)  # Any use of vw object should be done after this\n",
    "\n",
    "    sum_loss_since_last = vw.get_sum_loss() - sum_loss  # vw.get_sum_loss() return current sum loss, sum_loss variable right now holds sum loss of previous iteration\n",
    "    weighted_examples_since_last = vw.get_weighted_examples() - weighted_examples  # vw.get_weighted_examples() return current weighted examples(sum),  weighted_examples variable right now holds weighted examples of previous iteration\n",
    "        \n",
    "    sum_loss= vw.get_sum_loss()  # Now sum_loss no longer hold previous iteration's sum_loss\n",
    "    weighted_examples = vw.get_weighted_examples()  # Now weighted_examples no longer hold previous iteration's weighted examples\n",
    "    \n",
    "    average_loss = calculate_average_loss(sum_loss, weighted_examples)\n",
    "    since_last = calculate_since_last(sum_loss_since_last, weighted_examples_since_last)\n",
    "    \n",
    "    print( 'average_loss:{:.6f}'.format(average_loss) , end='\\t')\n",
    "    print('since_last:{:.6f}'.format(since_last), end='\\t')\n",
    "    print('label:', label, end='\\t')    \n",
    "    print('prediction:', prediction, end='\\t')    \n",
    "    print('features:', features)  \n",
    "    \n",
    "    file_writer.add_scalar('average_loss', average_loss, iteration)  # logging average_loss on each iteration\n",
    "    file_writer.add_scalar('since_last', since_last, iteration)   # logging since_last on each iteration\n",
    "#     file_writer.add_scalar('label' , label, iteration)\n",
    "#     file_writer.add_scalar('prediction', prediction, iteration)\n",
    "#     file_writer.add_histogram('label-prediction', [label, prediction], iteration)\n",
    "# #     file_writer.add_histogram('label', label, iteration)\n",
    "# #     file_writer.add_histogram('prediction', prediction, iteration)\n",
    "#     file_writer.add_scalar('features', features, iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
