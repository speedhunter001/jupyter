{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.684725522994995\n"
     ]
    }
   ],
   "source": [
    "#source  https://github.com/opencv/opencv/wiki/TensorFlow-Object-Detection-API\n",
    "\n",
    "import cv2 as cv\n",
    "import time \n",
    "#ssd v1 pp\n",
    "#cvNet = cv.dnn.readNetFromTensorflow('opencvtensorflvours/SSDv1ppn/ssd_mobilenet_v1_ppn_shared_box_predictor_300x300_coco14_sync_2018_07_03/frozen_inference_graph.pb', 'opencvtensorflvours/SSDv1ppn/ssd_mobilenet_v1_ppn_coco.pbtxt')\n",
    "\n",
    "##ssd v1 \n",
    "#cvNet = cv.dnn.readNetFromTensorflow('opencvtensorflvours/SSDv1/frozen_inference_graph.pb', 'opencvtensorflvours/SSDv1/ssd_mobilenet_v1coco.pbtxt')\n",
    "\n",
    "#ssd v2\n",
    "#cvNet = cv.dnn.readNetFromTensorflow('opencvtensorflvours/SSDv2/frozen_inference_graph.pb', 'opencvtensorflvours/SSDv2/ssd_mobilenet_v2_coco_2018_03_29.pbtxt')\n",
    "\n",
    "#faster rcnn resnet50\n",
    "cvNet = cv.dnn.readNetFromTensorflow('opencvtensorflvours/fastrcnn/frozen_inference_graph.pb', 'opencvtensorflvours/fastrcnn/faster_rcnn_resnet50.pbtxt')\n",
    "\n",
    "#ssd inception v2\n",
    "#cvNet = cv.dnn.readNetFromTensorflow('opencvtensorflvours/ssdincept/frozen_inference_graph.pb', 'opencvtensorflvours/ssdincept/ssd_inception_v2_coco_2017_11_17.pbtxt')\n",
    "\n",
    "#faster rcnn inception\n",
    "#cvNet = cv.dnn.readNetFromTensorflow('opencvtensorflvours/fastrcnnincept/frozen_inference_graph.pb', 'opencvtensorflvours/fastrcnnincept/faster_rcnn_inception_v2_coco_2018_01_28.pbtxt')\n",
    "\n",
    "\n",
    "img = cv.imread('addog.jpg')\n",
    "rows = img.shape[0]\n",
    "cols = img.shape[1]\n",
    "cvNet.setInput(cv.dnn.blobFromImage(img, size=(300, 300), swapRB=True, crop=False))\n",
    "st = time.time()\n",
    "cvOut = cvNet.forward()\n",
    "end = time.time()\n",
    "print(end - st)\n",
    "\n",
    "for detection in cvOut[0,0,:,:]:\n",
    "    score = float(detection[2])\n",
    "      \n",
    "    if score > 0.5:\n",
    "        left = detection[3] * cols\n",
    "        top = detection[4] * rows\n",
    "        right = detection[5] * cols\n",
    "        bottom = detection[6] * rows\n",
    "        cv.rectangle(img, (int(left), int(top)), (int(right), int(bottom)), (23, 230, 210), thickness=2)\n",
    "                \n",
    "        classID = int(detection[1] -1)\n",
    "\n",
    "        text = \"{}: {:.3f}\".format(LABELS[classID], score)\n",
    "        \n",
    "        cv.putText(img, text, (int(left), int(top) - 5),cv.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 2)\n",
    "\n",
    "cv.imshow('img', img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'street sign', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'hat', 'backpack', 'umbrella', 'shoe', 'eye glasses', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'plate', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'mirror', 'dining table', 'window', 'desk', 'toilet', 'door', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'blender', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush', 'hair brush']\n",
      "91\n"
     ]
    }
   ],
   "source": [
    "labelsPath =  'opencvtensorflvours/coco.names'\n",
    "#os.path.sep.join(['pathhere', \"coco.names\"])\n",
    "LABELS = open(labelsPath).read().strip().split(\"\\n\")\n",
    "print(LABELS)\n",
    "print(len(LABELS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cell phone'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABELS[76]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.882393836975098\n",
      "(1, 1, 100, 7)\n",
      "-1\n",
      "-1\n",
      "1\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "#source  https://github.com/opencv/opencv/wiki/TensorFlow-Object-Detection-API\n",
    "\n",
    "import cv2 as cv\n",
    "import time \n",
    "#ssd v1 pp  #worksl\n",
    "cvNet = cv.dnn.readNetFromTensorflow('opencvtensorflvours/SSDv1ppn/ssd_mobilenet_v1_ppn_shared_box_predictor_300x300_coco14_sync_2018_07_03/frozen_inference_graph.pb', 'opencvtensorflvours/SSDv1ppn/ssd_mobilenet_v1_ppn_coco.pbtxt')\n",
    "\n",
    "##ssd v1  #worksl\n",
    "#cvNet = cv.dnn.readNetFromTensorflow('opencvtensorflvours/SSDv1/frozen_inference_graph.pb', 'opencvtensorflvours/SSDv1/ssd_mobilenet_v1coco.pbtxt')\n",
    "\n",
    "#ssd v2 #worksl\n",
    "#cvNet = cv.dnn.readNetFromTensorflow('opencvtensorflvours/SSDv2/frozen_inference_graph.pb', 'opencvtensorflvours/SSDv2/ssd_mobilenet_v2_coco_2018_03_29.pbtxt')\n",
    "#faster rcnn resnet50  #worksl without -1  # not for real time\n",
    "cvNet = cv.dnn.readNetFromTensorflow('opencvtensorflvours/fastrcnn/frozen_inference_graph.pb', 'opencvtensorflvours/fastrcnn/faster_rcnn_resnet50.pbtxt')\n",
    "\n",
    "#ssd inception v2  #worksl\n",
    "#cvNet = cv.dnn.readNetFromTensorflow('opencvtensorflvours/ssdincept/frozen_inference_graph.pb', 'opencvtensorflvours/ssdincept/ssd_inception_v2_coco_2017_11_17.pbtxt')\n",
    "\n",
    "#faster rcnn inception #works l without -1\n",
    "#cvNet = cv.dnn.readNetFromTensorflow('opencvtensorflvours/fastrcnnincept/frozen_inference_graph.pb', 'opencvtensorflvours/fastrcnnincept/faster_rcnn_inception_v2_coco_2018_01_28.pbtxt')\n",
    "import numpy as np\n",
    "\n",
    "img = cv.imread('example_02.jpg')\n",
    "rows = img.shape[0]\n",
    "cols = img.shape[1]\n",
    "cvNet.setInput(cv.dnn.blobFromImage(img, size=(300, 300), swapRB=True, crop=False))\n",
    "st = time.time()\n",
    "boxes = cvNet.forward()\n",
    "end = time.time()\n",
    "np.random.seed(50)\n",
    "COLORS = np.random.randint(0, 255, size=(len(LABELS), 3))\n",
    "print(end - st)\n",
    "print(boxes.shape)\n",
    "for i in range(0, boxes.shape[2]):\n",
    "        classID =  int((boxes[0, 0, i, 1])-1)\n",
    "        #classID =  int((boxes[0, 0, i, 1]))\n",
    "\n",
    "        confidence = boxes[0, 0, i, 2]\n",
    "        if confidence > 0.5:\n",
    "            print(classID)\n",
    "\n",
    "            left = boxes[0,0,i,3] * cols\n",
    "            top = boxes[0,0,i,4] * rows\n",
    "            right = boxes[0,0,i,5] * cols\n",
    "            bottom = boxes[0,0,i,6] * rows\n",
    "            color = COLORS[classID]\n",
    "            color = [int(c) for c in color]\n",
    "\n",
    "            cv.rectangle(img, (int(left), int(top)), (int(right), int(bottom)), color, thickness=2)\n",
    "\n",
    "\n",
    "            text = \"{}: {:.3f}\".format(LABELS[classID], confidence)\n",
    "\n",
    "            cv.putText(img, text, (int(left), int(top) - 5),cv.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 2)\n",
    "\n",
    "cv.imshow('img', img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source  https://github.com/opencv/opencv/wiki/TensorFlow-Object-Detection-API\n",
    "\n",
    "import cv2 as cv\n",
    "import time \n",
    "#ssd v1 pp  #worksl 2.6 not very accurate\n",
    "#cvNet = cv.dnn.readNetFromTensorflow('opencvtensorflvours/SSDv1ppn/ssd_mobilenet_v1_ppn_shared_box_predictor_300x300_coco14_sync_2018_07_03/frozen_inference_graph.pb', 'opencvtensorflvours/SSDv1ppn/ssd_mobilenet_v1_ppn_coco.pbtxt')\n",
    "\n",
    "##ssd v1  #worksl   2.6  accurate\n",
    "cvNet = cv.dnn.readNetFromTensorflow('opencvtensorflvours/SSDv1/frozen_inference_graph.pb', 'opencvtensorflvours/SSDv1/ssd_mobilenet_v1coco.pbtxt')\n",
    "\n",
    "#ssd v2 #worksl  2 accurate\n",
    "#cvNet = cv.dnn.readNetFromTensorflow('opencvtensorflvours/SSDv2/frozen_inference_graph.pb', 'opencvtensorflvours/SSDv2/ssd_mobilenet_v2_coco_2018_03_29.pbtxt')\n",
    "\n",
    "#faster rcnn resnet50  #worksl without - 1 not for real time\n",
    "#cvNet = cv.dnn.readNetFromTensorflow('opencvtensorflvours/fastrcnn/frozen_inference_graph.pb', 'opencvtensorflvours/fastrcnn/faster_rcnn_resnet50.pbtxt')\n",
    "\n",
    "#ssd inception v2  #worksl 1.5 accurate\n",
    "#cvNet = cv.dnn.readNetFromTensorflow('opencvtensorflvours/ssdincept/frozen_inference_graph.pb', 'opencvtensorflvours/ssdincept/ssd_inception_v2_coco_2017_11_17.pbtxt')\n",
    "\n",
    "#faster rcnn inception #works l without -1   0.4 fps  \n",
    "#cvNet = cv.dnn.readNetFromTensorflow('opencvtensorflvours/fastrcnnincept/frozen_inference_graph.pb', 'opencvtensorflvours/fastrcnnincept/faster_rcnn_inception_v2_coco_2018_01_28.pbtxt')\n",
    "import numpy as np\n",
    "import cv2\n",
    "cap = cv2.VideoCapture(0)\n",
    "cv2.namedWindow('image2', cv2.WINDOW_NORMAL)\n",
    "np.random.seed(50)\n",
    "COLORS = np.random.randint(0, 255, size=(len(LABELS), 3))\n",
    "fps= 0\n",
    "while True:\n",
    "    st = time.time()\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    img = cv2.flip( frame, 1 ) \n",
    "    rows = img.shape[0]\n",
    "    cols = img.shape[1]\n",
    "    blob = cv2.dnn.blobFromImage(img, size=(300, 300), swapRB=True, crop=False)\n",
    "    cv2.putText(img, 'FPS: {:.2f}'.format(fps), (20, 20),fontFace=cv2.FONT_HERSHEY_SIMPLEX,fontScale=0.3,color=(0, 0, 255))\n",
    "\n",
    "    cvNet.setInput(blob)\n",
    "    boxes = cvNet.forward()\n",
    "    end = time.time()\n",
    "\n",
    "    for i in range(0, boxes.shape[2]):\n",
    "            classID =  int((boxes[0, 0, i, 1])-1)\n",
    "            classID =  int((boxes[0, 0, i, 1]))\n",
    "\n",
    "            confidence = boxes[0, 0, i, 2]\n",
    "            if confidence > 0.5:\n",
    "\n",
    "                left = boxes[0,0,i,3] * cols\n",
    "                top = boxes[0,0,i,4] * rows\n",
    "                right = boxes[0,0,i,5] * cols\n",
    "                bottom = boxes[0,0,i,6] * rows\n",
    "                color = COLORS[classID]\n",
    "                color = [int(c) for c in color]\n",
    "\n",
    "                cv2.rectangle(img, (int(left), int(top)), (int(right), int(bottom)), color, thickness=2)\n",
    "\n",
    "\n",
    "                text = \"{}: {:.3f}\".format(LABELS[classID], confidence)\n",
    "\n",
    "                cv2.putText(img, text, (int(left), int(top) - 5),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 2)\n",
    "                \n",
    "    cv2.imshow('image2', img)\n",
    "    fps= (1.0 / (time.time() - st))\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hell\n"
     ]
    }
   ],
   "source": [
    "print('hell')\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2 as cv\n",
    "\n",
    "# Read the graph.\n",
    "with tf.gfile.FastGFile('opencvtensorflvours/SSDv1/frozen_inference_graph.pb', 'rb') as f:\n",
    "    graph_def = tf.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Restore session\n",
    "    sess.graph.as_default()\n",
    "    tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "    # Read and preprocess an image.\n",
    "    img = cv.imread('yolotest2.jpg')\n",
    "    rows = img.shape[0]\n",
    "    cols = img.shape[1]\n",
    "    inp = cv.resize(img, (300, 300))\n",
    "    inp = inp[:, :, [2, 1, 0]]  # BGR2RGB\n",
    "\n",
    "    # Run the model\n",
    "    out = sess.run([sess.graph.get_tensor_by_name('num_detections:0'),\n",
    "                    sess.graph.get_tensor_by_name('detection_scores:0'),\n",
    "                    sess.graph.get_tensor_by_name('detection_boxes:0'),\n",
    "                    sess.graph.get_tensor_by_name('detection_classes:0')],\n",
    "                   feed_dict={'image_tensor:0': inp.reshape(1, inp.shape[0], inp.shape[1], 3)})\n",
    "\n",
    "    # Visualize detected bounding boxes.\n",
    "    num_detections = int(out[0][0])\n",
    "    for i in range(num_detections):\n",
    "        classId = int(out[3][0][i])\n",
    "        score = float(out[1][0][i])\n",
    "        bbox = [float(v) for v in out[2][0][i]]\n",
    "        if score > 0.5:\n",
    "            x = bbox[1] * cols\n",
    "            y = bbox[0] * rows\n",
    "            right = bbox[3] * cols\n",
    "            bottom = bbox[2] * rows\n",
    "            cv.rectangle(img, (int(x), int(y)), (int(right), int(bottom)), (125, 255, 51), thickness=2)\n",
    "\n",
    "cv.imshow('TensorFlow MobileNet-SSD', img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-1905a0d3ff89>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[0mnum_detections\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_detections\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m                 \u001b[0mclassId\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m                 \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m                 \u001b[0mbbox\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2 as cv\n",
    "\n",
    "# Read the graph.\n",
    "with tf.gfile.FastGFile('opencvtensorflvours/SSDv1/frozen_inference_graph.pb', 'rb') as f:\n",
    "    graph_def = tf.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())\n",
    "\n",
    "cap = cv2.VideoCapture(0)    \n",
    "with detection_graph.as_default():\n",
    "    with tf.Session(graph=detection_graph) as sess:    \n",
    "      while True:\n",
    "        \n",
    "            # Read and preprocess an image.\n",
    "            ret, img = cap.read()\n",
    "            rows = img.shape[0]\n",
    "            cols = img.shape[1]\n",
    "            inp = cv.resize(img, (300, 300))\n",
    "            inp = inp[:, :, [2, 1, 0]]  # BGR2RGB\n",
    "\n",
    "            # Run the model\n",
    "            out = sess.run([sess.graph.get_tensor_by_name('num_detections:0'),\n",
    "                            sess.graph.get_tensor_by_name('detection_scores:0'),\n",
    "                            sess.graph.get_tensor_by_name('detection_boxes:0'),\n",
    "                            sess.graph.get_tensor_by_name('detection_classes:0')],\n",
    "                           feed_dict={'image_tensor:0': inp.reshape(1, inp.shape[0], inp.shape[1], 3)})\n",
    "\n",
    "            # Visualize detected bounding boxes.\n",
    "            num_detections = int(out[0][0])\n",
    "            for i in range(num_detections):\n",
    "                classId = int(out[3][0][i])\n",
    "                score = float(out[1][0][i])\n",
    "                bbox = [float(v) for v in out[2][0][i]]\n",
    "                if score > 0.5:\n",
    "                    x = bbox[1] * cols\n",
    "                    y = bbox[0] * rows\n",
    "                    right = bbox[3] * cols\n",
    "                    bottom = bbox[2] * rows\n",
    "                    print(classID)\n",
    "\n",
    "                    cv.rectangle(img, (int(x), int(y)), (int(right), int(bottom)), (125, 255, 51), thickness=2)\n",
    "                    text = \"{}: {:.3f}\".format(LABELS[classID], score)\n",
    "        \n",
    "                    cv.putText(img, text, (int(x), int(y) - 5),cv.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 2)\n",
    "\n",
    "            cv.imshow('TensorFlow MobileNet-SSD', img)\n",
    "            if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "                cv.destroyAllWindows()\n",
    "                cap.release()\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "#import six.moves.urllib as urllib\n",
    "import sys\n",
    "#import tarfile\n",
    "import tensorflow as tf\n",
    "#import zipfile\n",
    "import cv2\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "#from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from utils import label_map_util\n",
    "from utils import visualization_utils as vis_util\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "PATH_TO_CKPT = 'opencvtensorflvours/SSDv1/frozen_inference_graph.pb'\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = 'mscoco_label_map.pbtxt'\n",
    "\n",
    "# Number of classes to detect\n",
    "NUM_CLASSES = 90\n",
    "\n",
    "# Load a (frozen) Tensorflow model into memory.\n",
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')\n",
    "\n",
    "\n",
    "# Loading label map\n",
    "# Label maps map indices to category names, so that when our convolution network predicts `5`, we know that this corresponds to `airplane`.  Here we use internal utility functions, but anything that returns a dictionary mapping integers to appropriate string labels would be fine\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(\n",
    "    label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Detection\n",
    "with detection_graph.as_default():\n",
    "    with tf.Session(graph=detection_graph) as sess:\n",
    "        while True:\n",
    "\n",
    "            # Read frame from camera\n",
    "            ret, image_np = cap.read()\n",
    "            image_np = cv.resize(image_np, (300, 300))\n",
    "            # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "            image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "            # Extract image tensor\n",
    "            image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "            # Extract detection boxes\n",
    "            boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "            # Extract detection scores\n",
    "            scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "            # Extract detection classes\n",
    "            classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "           # print(scores,boxes,classes)\n",
    "\n",
    "            # Extract number of detectionsd\n",
    "            num_detections = detection_graph.get_tensor_by_name(\n",
    "                'num_detections:0')\n",
    "            # Actual detection.\n",
    "            (boxes, scores, classes, num_detections) = sess.run(\n",
    "                [boxes, scores, classes, num_detections],\n",
    "                feed_dict={image_tensor: image_np_expanded})\n",
    "            # Visualization of the results of a detection.\n",
    "            vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np,\n",
    "                np.squeeze(boxes),\n",
    "                np.squeeze(classes).astype(np.int32),\n",
    "                np.squeeze(scores),\n",
    "                category_index,\n",
    "                use_normalized_coordinates=True,\n",
    "                line_thickness=8)\n",
    "\n",
    "            # Display output\n",
    "            cv2.imshow('object detection', cv2.resize(image_np, (800, 600)))\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                cv2.destroyAllWindows()\n",
    "                cap.release()\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1., 62., 62., 62., 62.,  1., 84., 62., 84., 62., 62., 84., 84.,\n",
       "       84.,  1.,  1., 84., 62., 62.,  1., 62., 62., 62.,  1., 62., 62.,\n",
       "        1.,  1.,  1.,  1., 62., 84., 72.,  1.,  1.,  1.,  1., 62., 77.,\n",
       "       84.,  1.,  1., 62., 62., 62.,  1.,  1.,  1., 62.,  1.,  1.,  1.,\n",
       "       60., 62., 62.,  1., 62.,  1.,  1.,  1., 62., 77., 62., 60.,  1.,\n",
       "        1.,  1.,  1., 84., 72., 27.,  1., 84., 72., 72.,  1., 31., 84.,\n",
       "        1., 62.,  1.,  1., 90., 62.,  1.,  1.,  1., 62., 62., 90.,  1.,\n",
       "       62., 84., 84., 77., 84.,  1.,  1., 84., 90.], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[3][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.1.0) C:\\projects\\opencv-python\\opencv\\modules\\dnn\\src\\tensorflow\\tf_io.cpp:42: error: (-2:Unspecified error) FAILED: ReadProtoFromBinaryFile(param_file, param). Failed to parse GraphDef file: saved_model.pb in function 'cv::dnn::ReadTFNetParamsFromBinaryFileOrDie'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-4c221ac4f494>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#cvNet = cv.dnn.readNetFromTensorflow('saved_model.pb')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mcvNet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'saved_model.pb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.1.0) C:\\projects\\opencv-python\\opencv\\modules\\dnn\\src\\tensorflow\\tf_io.cpp:42: error: (-2:Unspecified error) FAILED: ReadProtoFromBinaryFile(param_file, param). Failed to parse GraphDef file: saved_model.pb in function 'cv::dnn::ReadTFNetParamsFromBinaryFileOrDie'\n"
     ]
    }
   ],
   "source": [
    "#source  https://github.com/opencv/opencv/wiki/TensorFlow-Object-Detection-API\n",
    "\n",
    "import cv2 as cv\n",
    "import time \n",
    "\n",
    "#cvNet = cv.dnn.readNetFromTensorflow('saved_model.pb')\n",
    "cvNet = cv.dnn.readNet('saved_model.pb')\n",
    "import numpy as np\n",
    "\n",
    "img = cv.imread('example_02.jpg')\n",
    "rows = img.shape[0]\n",
    "cols = img.shape[1]\n",
    "cvNet.setInput(cv.dnn.blobFromImage(img, size=(300, 300), swapRB=True, crop=False))\n",
    "st = time.time()\n",
    "boxes = cvNet.forward()\n",
    "end = time.time()\n",
    "np.random.seed(50)\n",
    "COLORS = np.random.randint(0, 255, size=(len(LABELS), 3))\n",
    "print(end - st)\n",
    "print(boxes.shape)\n",
    "for i in range(0, boxes.shape[2]):\n",
    "        classID =  int((boxes[0, 0, i, 1])-1)\n",
    "        #classID =  int((boxes[0, 0, i, 1]))\n",
    "\n",
    "        confidence = boxes[0, 0, i, 2]\n",
    "        if confidence > 0.5:\n",
    "            print(classID)\n",
    "\n",
    "            left = boxes[0,0,i,3] * cols\n",
    "            top = boxes[0,0,i,4] * rows\n",
    "            right = boxes[0,0,i,5] * cols\n",
    "            bottom = boxes[0,0,i,6] * rows\n",
    "            color = COLORS[classID]\n",
    "            color = [int(c) for c in color]\n",
    "\n",
    "            cv.rectangle(img, (int(left), int(top)), (int(right), int(bottom)), color, thickness=2)\n",
    "\n",
    "\n",
    "            text = \"{}: {:.3f}\".format(LABELS[classID], confidence)\n",
    "\n",
    "            cv.putText(img, text, (int(left), int(top) - 5),cv.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 2)\n",
    "\n",
    "cv.imshow('img', img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
